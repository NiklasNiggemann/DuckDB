
=== Phase 1: Running benchmarks ===

[START] polars - normal

------------------------------------------------

[NORMAL] Reading a table with ca. 2.2 GB ...

------------------------------------------------

1139264
Filename: /Users/niklasniggemann/duckdb_motherduck_lab/duckdb_polars_stresstest/polars_olap.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
     6     71.3 MiB     71.3 MiB           1   @profile
     7                                         def normal_test(scale_factor: int):
     8     71.3 MiB      0.0 MiB           1       parquet_path = f"tpc/lineitem_{scale_factor}.parquet"
     9    196.6 MiB      0.0 MiB           1       df = (
    10     71.6 MiB      0.3 MiB           1           pl.scan_parquet(parquet_path)
    11     72.0 MiB      0.1 MiB           2           .filter(
    12     71.9 MiB      0.3 MiB           4               (pl.col("l_shipdate") >= date(1994, 1, 1)) &
    13     71.8 MiB      0.0 MiB           1               (pl.col("l_shipdate") <  date(1995, 1, 1)) &
    14     71.9 MiB      0.0 MiB           1               (pl.col("l_discount").is_between(0.05, 0.07)) &
    15     71.9 MiB      0.0 MiB           1               (pl.col("l_quantity") < 24)
    16                                                 )
    17     72.1 MiB      0.1 MiB           1           .select(pl.len().alias("cnt"))
    18    196.6 MiB    124.5 MiB           1           .collect(engine="streaming")
    19                                             )
    20    196.7 MiB      0.1 MiB           1       print(df['cnt'][0])


Memory = 125.55 MB, Time = 0.09 s

------------------------------------------------

[NORMAL] Reading a table with ca. 4.4 GB ...

------------------------------------------------

2281119
Filename: /Users/niklasniggemann/duckdb_motherduck_lab/duckdb_polars_stresstest/polars_olap.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
     6     71.0 MiB     71.0 MiB           1   @profile
     7                                         def normal_test(scale_factor: int):
     8     71.0 MiB      0.0 MiB           1       parquet_path = f"tpc/lineitem_{scale_factor}.parquet"
     9    198.9 MiB      0.0 MiB           1       df = (
    10     71.3 MiB      0.3 MiB           1           pl.scan_parquet(parquet_path)
    11     71.8 MiB      0.1 MiB           2           .filter(
    12     71.6 MiB      0.3 MiB           4               (pl.col("l_shipdate") >= date(1994, 1, 1)) &
    13     71.5 MiB      0.0 MiB           1               (pl.col("l_shipdate") <  date(1995, 1, 1)) &
    14     71.6 MiB      0.0 MiB           1               (pl.col("l_discount").is_between(0.05, 0.07)) &
    15     71.6 MiB      0.0 MiB           1               (pl.col("l_quantity") < 24)
    16                                                 )
    17     71.8 MiB      0.1 MiB           1           .select(pl.len().alias("cnt"))
    18    198.9 MiB    127.0 MiB           1           .collect(engine="streaming")
    19                                             )
    20    199.0 MiB      0.1 MiB           1       print(df['cnt'][0])


Memory = 128.11 MB, Time = 0.27 s

------------------------------------------------

[NORMAL] Reading a table with ca. 8.8 GB ...

------------------------------------------------

4565749
Filename: /Users/niklasniggemann/duckdb_motherduck_lab/duckdb_polars_stresstest/polars_olap.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
     6     71.2 MiB     71.2 MiB           1   @profile
     7                                         def normal_test(scale_factor: int):
     8     71.2 MiB      0.0 MiB           1       parquet_path = f"tpc/lineitem_{scale_factor}.parquet"
     9    231.2 MiB      0.0 MiB           1       df = (
    10     71.5 MiB      0.3 MiB           1           pl.scan_parquet(parquet_path)
    11     72.0 MiB      0.1 MiB           2           .filter(
    12     71.8 MiB      0.3 MiB           4               (pl.col("l_shipdate") >= date(1994, 1, 1)) &
    13     71.8 MiB      0.0 MiB           1               (pl.col("l_shipdate") <  date(1995, 1, 1)) &
    14     71.8 MiB      0.0 MiB           1               (pl.col("l_discount").is_between(0.05, 0.07)) &
    15     71.8 MiB      0.0 MiB           1               (pl.col("l_quantity") < 24)
    16                                                 )
    17     72.0 MiB      0.1 MiB           1           .select(pl.len().alias("cnt"))
    18    231.2 MiB    159.2 MiB           1           .collect(engine="streaming")
    19                                             )
    20    231.3 MiB      0.1 MiB           1       print(df['cnt'][0])


Memory = 160.22 MB, Time = 0.54 s

------------------------------------------------

[NORMAL] Reading a table with ca. 17.6 GB ...

------------------------------------------------

9135381
Filename: /Users/niklasniggemann/duckdb_motherduck_lab/duckdb_polars_stresstest/polars_olap.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
     6     71.0 MiB     71.0 MiB           1   @profile
     7                                         def normal_test(scale_factor: int):
     8     71.0 MiB      0.0 MiB           1       parquet_path = f"tpc/lineitem_{scale_factor}.parquet"
     9    274.2 MiB      0.0 MiB           1       df = (
    10     71.3 MiB      0.3 MiB           1           pl.scan_parquet(parquet_path)
    11     71.8 MiB      0.1 MiB           2           .filter(
    12     71.7 MiB      0.3 MiB           4               (pl.col("l_shipdate") >= date(1994, 1, 1)) &
    13     71.6 MiB      0.0 MiB           1               (pl.col("l_shipdate") <  date(1995, 1, 1)) &
    14     71.6 MiB      0.0 MiB           1               (pl.col("l_discount").is_between(0.05, 0.07)) &
    15     71.7 MiB      0.0 MiB           1               (pl.col("l_quantity") < 24)
    16                                                 )
    17     71.9 MiB      0.1 MiB           1           .select(pl.len().alias("cnt"))
    18    274.2 MiB    202.3 MiB           1           .collect(engine="streaming")
    19                                             )
    20    274.3 MiB      0.1 MiB           1       print(df['cnt'][0])


Memory = 203.42 MB, Time = 1.06 s

------------------------------------------------

[NORMAL] Reading a table with ca. 35.2 GB ...

------------------------------------------------

18269118
Filename: /Users/niklasniggemann/duckdb_motherduck_lab/duckdb_polars_stresstest/polars_olap.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
     6     71.1 MiB     71.1 MiB           1   @profile
     7                                         def normal_test(scale_factor: int):
     8     71.1 MiB      0.0 MiB           1       parquet_path = f"tpc/lineitem_{scale_factor}.parquet"
     9    348.6 MiB      0.0 MiB           1       df = (
    10     71.4 MiB      0.3 MiB           1           pl.scan_parquet(parquet_path)
    11     71.9 MiB      0.1 MiB           2           .filter(
    12     71.7 MiB      0.3 MiB           4               (pl.col("l_shipdate") >= date(1994, 1, 1)) &
    13     71.7 MiB      0.0 MiB           1               (pl.col("l_shipdate") <  date(1995, 1, 1)) &
    14     71.7 MiB      0.0 MiB           1               (pl.col("l_discount").is_between(0.05, 0.07)) &
    15     71.7 MiB      0.0 MiB           1               (pl.col("l_quantity") < 24)
    16                                                 )
    17     71.9 MiB      0.1 MiB           1           .select(pl.len().alias("cnt"))
    18    348.6 MiB    276.6 MiB           1           .collect(engine="streaming")
    19                                             )
    20    348.7 MiB      0.1 MiB           1       print(df['cnt'][0])


Memory = 277.72 MB, Time = 2.06 s

------------------------------------------------

[NORMAL] Reading a table with ca. 70.4 GB ...

------------------------------------------------

36542597
Filename: /Users/niklasniggemann/duckdb_motherduck_lab/duckdb_polars_stresstest/polars_olap.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
     6     71.2 MiB     71.2 MiB           1   @profile
     7                                         def normal_test(scale_factor: int):
     8     71.2 MiB      0.0 MiB           1       parquet_path = f"tpc/lineitem_{scale_factor}.parquet"
     9    694.3 MiB    -37.2 MiB           1       df = (
    10     71.5 MiB      0.3 MiB           1           pl.scan_parquet(parquet_path)
    11     72.0 MiB      0.1 MiB           2           .filter(
    12     71.8 MiB      0.3 MiB           4               (pl.col("l_shipdate") >= date(1994, 1, 1)) &
    13     71.8 MiB      0.0 MiB           1               (pl.col("l_shipdate") <  date(1995, 1, 1)) &
    14     71.8 MiB      0.0 MiB           1               (pl.col("l_discount").is_between(0.05, 0.07)) &
    15     71.8 MiB      0.0 MiB           1               (pl.col("l_quantity") < 24)
    16                                                 )
    17     72.0 MiB      0.1 MiB           1           .select(pl.len().alias("cnt"))
    18    731.5 MiB    659.5 MiB           1           .collect(engine="streaming")
    19                                             )
    20    504.6 MiB   -189.7 MiB           1       print(df['cnt'][0])


Memory = 433.53 MB, Time = 4.26 s

------------------------------------------------

[NORMAL] Reading a table with ca. 140.8 GB ...

------------------------------------------------

73100039
Filename: /Users/niklasniggemann/duckdb_motherduck_lab/duckdb_polars_stresstest/polars_olap.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
     6     71.1 MiB     71.1 MiB           1   @profile
     7                                         def normal_test(scale_factor: int):
     8     71.1 MiB      0.0 MiB           1       parquet_path = f"tpc/lineitem_{scale_factor}.parquet"
     9    748.6 MiB      0.1 MiB           1       df = (
    10     71.4 MiB      0.3 MiB           1           pl.scan_parquet(parquet_path)
    11     71.9 MiB      0.1 MiB           2           .filter(
    12     71.8 MiB      0.3 MiB           4               (pl.col("l_shipdate") >= date(1994, 1, 1)) &
    13     71.7 MiB      0.0 MiB           1               (pl.col("l_shipdate") <  date(1995, 1, 1)) &
    14     71.7 MiB      0.0 MiB           1               (pl.col("l_discount").is_between(0.05, 0.07)) &
    15     71.8 MiB      0.0 MiB           1               (pl.col("l_quantity") < 24)
    16                                                 )
    17     72.0 MiB      0.1 MiB           1           .select(pl.len().alias("cnt"))
    18    748.5 MiB    676.5 MiB           1           .collect(engine="streaming")
    19                                             )
    20    750.0 MiB      1.4 MiB           1       print(df['cnt'][0])


Memory = 679.67 MB, Time = 9.40 s

--- Elapsed Time (s) ---
Mean:   2.53
Std:    3.36
CV:     132.9%
Min:    0.09
Max:    9.40
Span:   9.31

------------------------------------------------

--- Memory Used (MB) ---
Mean:   286.89
Std:    204.17
CV:     71.2%
Min:    125.55
Max:    679.67
Span:   554.12

------------------------------------------------

[START] polars - stress

------------------------------------------------

[STRESS] Reading 2 tables with ca. 280 GB ...

------------------------------------------------

146200078
Filename: /Users/niklasniggemann/duckdb_motherduck_lab/duckdb_polars_stresstest/polars_olap.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    22     71.1 MiB     71.1 MiB           1   @profile
    23                                         def stress_test(scale_factors: List[int]):
    24     71.1 MiB      0.0 MiB           3       parquet_files = [f"tpc/lineitem_{sf}.parquet" for sf in scale_factors]
    25   1422.3 MiB      0.2 MiB           1       df = (
    26     71.4 MiB      0.3 MiB           1           pl.scan_parquet(parquet_files)
    27     71.8 MiB      0.1 MiB           2           .filter(
    28     71.7 MiB      0.3 MiB           4               (pl.col("l_shipdate") >= date(1994, 1, 1)) &
    29     71.6 MiB      0.0 MiB           1               (pl.col("l_shipdate") <  date(1995, 1, 1)) &
    30     71.7 MiB      0.0 MiB           1               (pl.col("l_discount").is_between(0.05, 0.07)) &
    31     71.7 MiB      0.0 MiB           1               (pl.col("l_quantity") < 24)
    32                                                 )
    33     71.9 MiB      0.1 MiB           1           .select(pl.len().alias("cnt"))
    34   1422.2 MiB   1350.2 MiB           1           .collect(engine="streaming")
    35                                             )
    36   1423.9 MiB      1.6 MiB           1       print(df['cnt'][0])


Memory = 1353.72 MB, Time = 9.35 s

------------------------------------------------

[STRESS] Reading 4 tables with ca. 560 GB ...

------------------------------------------------

292400156
Filename: /Users/niklasniggemann/duckdb_motherduck_lab/duckdb_polars_stresstest/polars_olap.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    22     71.2 MiB     71.2 MiB           1   @profile
    23                                         def stress_test(scale_factors: List[int]):
    24     71.2 MiB      0.0 MiB           5       parquet_files = [f"tpc/lineitem_{sf}.parquet" for sf in scale_factors]
    25   1766.1 MiB     -0.6 MiB           1       df = (
    26     71.5 MiB      0.3 MiB           1           pl.scan_parquet(parquet_files)
    27     72.0 MiB      0.1 MiB           2           .filter(
    28     71.8 MiB      0.3 MiB           4               (pl.col("l_shipdate") >= date(1994, 1, 1)) &
    29     71.8 MiB      0.0 MiB           1               (pl.col("l_shipdate") <  date(1995, 1, 1)) &
    30     71.8 MiB      0.0 MiB           1               (pl.col("l_discount").is_between(0.05, 0.07)) &
    31     71.8 MiB      0.0 MiB           1               (pl.col("l_quantity") < 24)
    32                                                 )
    33     72.0 MiB      0.1 MiB           1           .select(pl.len().alias("cnt"))
    34   1766.7 MiB   1694.6 MiB           1           .collect(engine="streaming")
    35                                             )
    36   1764.6 MiB     -1.5 MiB           1       print(df['cnt'][0])


Memory = 1693.25 MB, Time = 20.81 s

------------------------------------------------

[STRESS] Reading 6 tables with ca. 840 GB ...

------------------------------------------------

438600234
Filename: /Users/niklasniggemann/duckdb_motherduck_lab/duckdb_polars_stresstest/polars_olap.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    22     71.2 MiB     71.2 MiB           1   @profile
    23                                         def stress_test(scale_factors: List[int]):
    24     71.2 MiB      0.0 MiB           7       parquet_files = [f"tpc/lineitem_{sf}.parquet" for sf in scale_factors]
    25   2015.8 MiB      0.2 MiB           1       df = (
    26     71.5 MiB      0.3 MiB           1           pl.scan_parquet(parquet_files)
    27     72.0 MiB      0.1 MiB           2           .filter(
    28     71.8 MiB      0.3 MiB           4               (pl.col("l_shipdate") >= date(1994, 1, 1)) &
    29     71.8 MiB      0.0 MiB           1               (pl.col("l_shipdate") <  date(1995, 1, 1)) &
    30     71.8 MiB      0.0 MiB           1               (pl.col("l_discount").is_between(0.05, 0.07)) &
    31     71.8 MiB      0.0 MiB           1               (pl.col("l_quantity") < 24)
    32                                                 )
    33     72.0 MiB      0.1 MiB           1           .select(pl.len().alias("cnt"))
    34   2015.7 MiB   1943.6 MiB           1           .collect(engine="streaming")
    35                                             )
    36   2016.2 MiB      0.4 MiB           1       print(df['cnt'][0])


Memory = 1941.83 MB, Time = 35.02 s

------------------------------------------------

[STRESS] Reading 8 tables with ca. 1120 GB ...

------------------------------------------------

584800312
Filename: /Users/niklasniggemann/duckdb_motherduck_lab/duckdb_polars_stresstest/polars_olap.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    22     71.3 MiB     71.3 MiB           1   @profile
    23                                         def stress_test(scale_factors: List[int]):
    24     71.3 MiB      0.0 MiB           9       parquet_files = [f"tpc/lineitem_{sf}.parquet" for sf in scale_factors]
    25   2093.0 MiB      0.2 MiB           1       df = (
    26     71.6 MiB      0.3 MiB           1           pl.scan_parquet(parquet_files)
    27     72.0 MiB      0.1 MiB           2           .filter(
    28     71.9 MiB      0.3 MiB           4               (pl.col("l_shipdate") >= date(1994, 1, 1)) &
    29     71.8 MiB      0.0 MiB           1               (pl.col("l_shipdate") <  date(1995, 1, 1)) &
    30     71.9 MiB      0.0 MiB           1               (pl.col("l_discount").is_between(0.05, 0.07)) &
    31     71.9 MiB      0.0 MiB           1               (pl.col("l_quantity") < 24)
    32                                                 )
    33     72.1 MiB      0.1 MiB           1           .select(pl.len().alias("cnt"))
    34   2092.8 MiB   2020.7 MiB           1           .collect(engine="streaming")
    35                                             )
    36   2094.9 MiB      1.9 MiB           1       print(df['cnt'][0])


Memory = 2024.73 MB, Time = 52.66 s

--- Elapsed Time (s) ---
Mean:   29.46
Std:    18.69
CV:     63.5%
Min:    9.35
Max:    52.66
Span:   43.31

------------------------------------------------

--- Memory Used (MB) ---
Mean:   1753.38
Std:    301.38
CV:     17.2%
Min:    1353.72
Max:    2024.73
Span:   671.01

------------------------------------------------

[START] polars - multiple

------------------------------------------------

[MULTIPLE] Reading 2 files (ca. 4 GB total)...

------------------------------------------------

2278528
Filename: /Users/niklasniggemann/duckdb_motherduck_lab/duckdb_polars_stresstest/polars_olap.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    38     71.4 MiB     71.4 MiB           1   @profile
    39                                         def multiple_test(num_files: int):
    40     71.4 MiB      0.0 MiB           1       parquet_files = [f"tpc/lineitem_10.parquet"] * num_files
    41    237.0 MiB      0.0 MiB           1       df = (
    42     71.6 MiB      0.3 MiB           1           pl.scan_parquet(parquet_files)
    43     72.1 MiB      0.1 MiB           2           .filter(
    44     72.0 MiB      0.3 MiB           4               (pl.col("l_shipdate") >= date(1994, 1, 1)) &
    45     71.9 MiB      0.0 MiB           1               (pl.col("l_shipdate") <  date(1995, 1, 1)) &
    46     72.0 MiB      0.0 MiB           1               (pl.col("l_discount").is_between(0.05, 0.07)) &
    47     72.0 MiB      0.0 MiB           1               (pl.col("l_quantity") < 24)
    48                                                 )
    49     72.2 MiB      0.1 MiB           1           .select(pl.len().alias("cnt"))
    50    237.0 MiB    164.8 MiB           1           .collect(engine="streaming")
    51                                             )
    52    237.1 MiB      0.1 MiB           1       print(df['cnt'][0])


Memory = 165.84 MB, Time = 0.21 s

------------------------------------------------

[MULTIPLE] Reading 4 files (ca. 8 GB total)...

------------------------------------------------

4557056
Filename: /Users/niklasniggemann/duckdb_motherduck_lab/duckdb_polars_stresstest/polars_olap.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    38     71.3 MiB     71.3 MiB           1   @profile
    39                                         def multiple_test(num_files: int):
    40     71.3 MiB      0.0 MiB           1       parquet_files = [f"tpc/lineitem_10.parquet"] * num_files
    41    382.5 MiB      0.0 MiB           1       df = (
    42     71.6 MiB      0.3 MiB           1           pl.scan_parquet(parquet_files)
    43     72.0 MiB      0.1 MiB           2           .filter(
    44     71.9 MiB      0.3 MiB           4               (pl.col("l_shipdate") >= date(1994, 1, 1)) &
    45     71.9 MiB      0.0 MiB           1               (pl.col("l_shipdate") <  date(1995, 1, 1)) &
    46     71.9 MiB      0.0 MiB           1               (pl.col("l_discount").is_between(0.05, 0.07)) &
    47     71.9 MiB      0.0 MiB           1               (pl.col("l_quantity") < 24)
    48                                                 )
    49     72.1 MiB      0.1 MiB           1           .select(pl.len().alias("cnt"))
    50    382.5 MiB    310.3 MiB           1           .collect(engine="streaming")
    51                                             )
    52    382.6 MiB      0.1 MiB           1       print(df['cnt'][0])


Memory = 311.42 MB, Time = 0.29 s

------------------------------------------------

[MULTIPLE] Reading 9 files (ca. 18 GB total)...

------------------------------------------------

10253376
Filename: /Users/niklasniggemann/duckdb_motherduck_lab/duckdb_polars_stresstest/polars_olap.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    38     71.2 MiB     71.2 MiB           1   @profile
    39                                         def multiple_test(num_files: int):
    40     71.2 MiB      0.0 MiB           1       parquet_files = [f"tpc/lineitem_10.parquet"] * num_files
    41    659.8 MiB      0.0 MiB           1       df = (
    42     71.5 MiB      0.3 MiB           1           pl.scan_parquet(parquet_files)
    43     71.9 MiB      0.1 MiB           2           .filter(
    44     71.8 MiB      0.3 MiB           4               (pl.col("l_shipdate") >= date(1994, 1, 1)) &
    45     71.7 MiB      0.0 MiB           1               (pl.col("l_shipdate") <  date(1995, 1, 1)) &
    46     71.8 MiB      0.0 MiB           1               (pl.col("l_discount").is_between(0.05, 0.07)) &
    47     71.8 MiB      0.0 MiB           1               (pl.col("l_quantity") < 24)
    48                                                 )
    49     72.0 MiB      0.1 MiB           1           .select(pl.len().alias("cnt"))
    50    659.8 MiB    587.8 MiB           1           .collect(engine="streaming")
    51                                             )
    52    660.0 MiB      0.1 MiB           1       print(df['cnt'][0])


Memory = 588.91 MB, Time = 0.62 s

------------------------------------------------

[MULTIPLE] Reading 18 files (ca. 36 GB total)...

------------------------------------------------

20506752
Filename: /Users/niklasniggemann/duckdb_motherduck_lab/duckdb_polars_stresstest/polars_olap.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    38     71.2 MiB     71.2 MiB           1   @profile
    39                                         def multiple_test(num_files: int):
    40     71.2 MiB      0.0 MiB           1       parquet_files = [f"tpc/lineitem_10.parquet"] * num_files
    41    851.1 MiB      0.0 MiB           1       df = (
    42     71.4 MiB      0.3 MiB           1           pl.scan_parquet(parquet_files)
    43     71.9 MiB      0.1 MiB           2           .filter(
    44     71.8 MiB      0.3 MiB           4               (pl.col("l_shipdate") >= date(1994, 1, 1)) &
    45     71.7 MiB      0.0 MiB           1               (pl.col("l_shipdate") <  date(1995, 1, 1)) &
    46     71.7 MiB      0.0 MiB           1               (pl.col("l_discount").is_between(0.05, 0.07)) &
    47     71.8 MiB      0.0 MiB           1               (pl.col("l_quantity") < 24)
    48                                                 )
    49     72.0 MiB      0.1 MiB           1           .select(pl.len().alias("cnt"))
    50    851.1 MiB    779.2 MiB           1           .collect(engine="streaming")
    51                                             )
    52    851.2 MiB      0.1 MiB           1       print(df['cnt'][0])


Memory = 780.23 MB, Time = 1.21 s

------------------------------------------------

[MULTIPLE] Reading 36 files (ca. 72 GB total)...

------------------------------------------------

41013504
Filename: /Users/niklasniggemann/duckdb_motherduck_lab/duckdb_polars_stresstest/polars_olap.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    38     71.2 MiB     71.2 MiB           1   @profile
    39                                         def multiple_test(num_files: int):
    40     71.2 MiB      0.0 MiB           1       parquet_files = [f"tpc/lineitem_10.parquet"] * num_files
    41    957.1 MiB      0.0 MiB           1       df = (
    42     71.5 MiB      0.3 MiB           1           pl.scan_parquet(parquet_files)
    43     71.9 MiB      0.1 MiB           2           .filter(
    44     71.8 MiB      0.3 MiB           4               (pl.col("l_shipdate") >= date(1994, 1, 1)) &
    45     71.7 MiB      0.0 MiB           1               (pl.col("l_shipdate") <  date(1995, 1, 1)) &
    46     71.8 MiB      0.0 MiB           1               (pl.col("l_discount").is_between(0.05, 0.07)) &
    47     71.8 MiB      0.0 MiB           1               (pl.col("l_quantity") < 24)
    48                                                 )
    49     72.0 MiB      0.1 MiB           1           .select(pl.len().alias("cnt"))
    50    957.1 MiB    885.1 MiB           1           .collect(engine="streaming")
    51                                             )
    52    957.2 MiB      0.1 MiB           1       print(df['cnt'][0])


Memory = 886.22 MB, Time = 2.37 s

------------------------------------------------

[MULTIPLE] Reading 72 files (ca. 144 GB total)...

------------------------------------------------

82027008
Filename: /Users/niklasniggemann/duckdb_motherduck_lab/duckdb_polars_stresstest/polars_olap.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    38     71.2 MiB     71.2 MiB           1   @profile
    39                                         def multiple_test(num_files: int):
    40     71.2 MiB      0.0 MiB           1       parquet_files = [f"tpc/lineitem_10.parquet"] * num_files
    41   1035.8 MiB      0.0 MiB           1       df = (
    42     71.5 MiB      0.3 MiB           1           pl.scan_parquet(parquet_files)
    43     71.9 MiB      0.1 MiB           2           .filter(
    44     71.8 MiB      0.3 MiB           4               (pl.col("l_shipdate") >= date(1994, 1, 1)) &
    45     71.7 MiB      0.0 MiB           1               (pl.col("l_shipdate") <  date(1995, 1, 1)) &
    46     71.8 MiB      0.0 MiB           1               (pl.col("l_discount").is_between(0.05, 0.07)) &
    47     71.8 MiB      0.0 MiB           1               (pl.col("l_quantity") < 24)
    48                                                 )
    49     72.0 MiB      0.1 MiB           1           .select(pl.len().alias("cnt"))
    50   1035.8 MiB    963.8 MiB           1           .collect(engine="streaming")
    51                                             )
    52   1035.9 MiB      0.1 MiB           1       print(df['cnt'][0])


Memory = 964.88 MB, Time = 4.89 s

--- Elapsed Time (s) ---
Mean:   1.60
Std:    1.80
CV:     112.5%
Min:    0.21
Max:    4.89
Span:   4.68

------------------------------------------------

--- Memory Used (MB) ---
Mean:   616.25
Std:    321.82
CV:     52.2%
Min:    165.84
Max:    964.88
Span:   799.04

------------------------------------------------

[START] duckdb - normal

------------------------------------------------

[NORMAL] Reading a table with ca. 2.2 GB ...

------------------------------------------------

1139264
Filename: /Users/niklasniggemann/duckdb_motherduck_lab/duckdb_polars_stresstest/duckdb_olap.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
     5     71.1 MiB     71.1 MiB           1   @profile
     6                                         def normal_test(scale_factor: int):
     7     73.8 MiB      2.7 MiB           1       con = duckdb.connect()
     8     73.8 MiB      0.0 MiB           1       parquet_path = f"tpc/lineitem_{scale_factor}.parquet"
     9     73.8 MiB      0.0 MiB           2       query = f"""
    10                                                 SELECT COUNT(*) AS cnt
    11     73.8 MiB      0.0 MiB           1           FROM read_parquet('{parquet_path}')
    12                                                 WHERE l_shipdate >= DATE '1994-01-01'
    13                                                   AND l_shipdate <  DATE '1995-01-01'
    14                                                   AND l_discount BETWEEN 0.05 AND 0.07
    15                                                   AND l_quantity < 24;
    16                                             """
    17    106.4 MiB     32.6 MiB           1       count = con.execute(query).fetchone()[0]
    18    106.4 MiB      0.0 MiB           1       print(count)
    19    106.3 MiB     -0.1 MiB           1       con.close()


Memory = 35.38 MB, Time = 0.10 s

------------------------------------------------

[NORMAL] Reading a table with ca. 4.4 GB ...

------------------------------------------------

2281119
Filename: /Users/niklasniggemann/duckdb_motherduck_lab/duckdb_polars_stresstest/duckdb_olap.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
     5     71.3 MiB     71.3 MiB           1   @profile
     6                                         def normal_test(scale_factor: int):
     7     74.0 MiB      2.8 MiB           1       con = duckdb.connect()
     8     74.0 MiB      0.0 MiB           1       parquet_path = f"tpc/lineitem_{scale_factor}.parquet"
     9     74.0 MiB      0.0 MiB           2       query = f"""
    10                                                 SELECT COUNT(*) AS cnt
    11     74.0 MiB      0.0 MiB           1           FROM read_parquet('{parquet_path}')
    12                                                 WHERE l_shipdate >= DATE '1994-01-01'
    13                                                   AND l_shipdate <  DATE '1995-01-01'
    14                                                   AND l_discount BETWEEN 0.05 AND 0.07
    15                                                   AND l_quantity < 24;
    16                                             """
    17    127.3 MiB     53.2 MiB           1       count = con.execute(query).fetchone()[0]
    18    127.3 MiB      0.0 MiB           1       print(count)
    19    127.2 MiB     -0.1 MiB           1       con.close()


Memory = 56.11 MB, Time = 0.26 s

------------------------------------------------

[NORMAL] Reading a table with ca. 8.8 GB ...

------------------------------------------------

4565749
Filename: /Users/niklasniggemann/duckdb_motherduck_lab/duckdb_polars_stresstest/duckdb_olap.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
     5     71.0 MiB     71.0 MiB           1   @profile
     6                                         def normal_test(scale_factor: int):
     7     73.7 MiB      2.7 MiB           1       con = duckdb.connect()
     8     73.7 MiB      0.0 MiB           1       parquet_path = f"tpc/lineitem_{scale_factor}.parquet"
     9     73.7 MiB      0.0 MiB           2       query = f"""
    10                                                 SELECT COUNT(*) AS cnt
    11     73.7 MiB      0.0 MiB           1           FROM read_parquet('{parquet_path}')
    12                                                 WHERE l_shipdate >= DATE '1994-01-01'
    13                                                   AND l_shipdate <  DATE '1995-01-01'
    14                                                   AND l_discount BETWEEN 0.05 AND 0.07
    15                                                   AND l_quantity < 24;
    16                                             """
    17    166.7 MiB     93.0 MiB           1       count = con.execute(query).fetchone()[0]
    18    166.7 MiB      0.0 MiB           1       print(count)
    19    166.6 MiB     -0.1 MiB           1       con.close()


Memory = 95.83 MB, Time = 0.45 s

------------------------------------------------

[NORMAL] Reading a table with ca. 17.6 GB ...

------------------------------------------------

9135381
Filename: /Users/niklasniggemann/duckdb_motherduck_lab/duckdb_polars_stresstest/duckdb_olap.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
     5     70.8 MiB     70.8 MiB           1   @profile
     6                                         def normal_test(scale_factor: int):
     7     73.4 MiB      2.7 MiB           1       con = duckdb.connect()
     8     73.4 MiB      0.0 MiB           1       parquet_path = f"tpc/lineitem_{scale_factor}.parquet"
     9     73.4 MiB      0.0 MiB           2       query = f"""
    10                                                 SELECT COUNT(*) AS cnt
    11     73.4 MiB      0.0 MiB           1           FROM read_parquet('{parquet_path}')
    12                                                 WHERE l_shipdate >= DATE '1994-01-01'
    13                                                   AND l_shipdate <  DATE '1995-01-01'
    14                                                   AND l_discount BETWEEN 0.05 AND 0.07
    15                                                   AND l_quantity < 24;
    16                                             """
    17    248.6 MiB    175.2 MiB           1       count = con.execute(query).fetchone()[0]
    18    248.6 MiB      0.0 MiB           1       print(count)
    19    242.5 MiB     -6.1 MiB           1       con.close()


Memory = 171.86 MB, Time = 0.88 s

------------------------------------------------

[NORMAL] Reading a table with ca. 35.2 GB ...

------------------------------------------------

18269118
Filename: /Users/niklasniggemann/duckdb_motherduck_lab/duckdb_polars_stresstest/duckdb_olap.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
     5     71.2 MiB     71.2 MiB           1   @profile
     6                                         def normal_test(scale_factor: int):
     7     73.8 MiB      2.6 MiB           1       con = duckdb.connect()
     8     73.8 MiB      0.0 MiB           1       parquet_path = f"tpc/lineitem_{scale_factor}.parquet"
     9     73.8 MiB      0.0 MiB           2       query = f"""
    10                                                 SELECT COUNT(*) AS cnt
    11     73.8 MiB      0.0 MiB           1           FROM read_parquet('{parquet_path}')
    12                                                 WHERE l_shipdate >= DATE '1994-01-01'
    13                                                   AND l_shipdate <  DATE '1995-01-01'
    14                                                   AND l_discount BETWEEN 0.05 AND 0.07
    15                                                   AND l_quantity < 24;
    16                                             """
    17    411.8 MiB    338.0 MiB           1       count = con.execute(query).fetchone()[0]
    18    411.8 MiB      0.0 MiB           1       print(count)
    19    411.8 MiB      0.0 MiB           1       con.close()


Memory = 340.75 MB, Time = 1.73 s

------------------------------------------------

[NORMAL] Reading a table with ca. 70.4 GB ...

------------------------------------------------

36542597
Filename: /Users/niklasniggemann/duckdb_motherduck_lab/duckdb_polars_stresstest/duckdb_olap.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
     5     71.1 MiB     71.1 MiB           1   @profile
     6                                         def normal_test(scale_factor: int):
     7     73.8 MiB      2.8 MiB           1       con = duckdb.connect()
     8     73.8 MiB      0.0 MiB           1       parquet_path = f"tpc/lineitem_{scale_factor}.parquet"
     9     73.8 MiB      0.0 MiB           2       query = f"""
    10                                                 SELECT COUNT(*) AS cnt
    11     73.8 MiB      0.0 MiB           1           FROM read_parquet('{parquet_path}')
    12                                                 WHERE l_shipdate >= DATE '1994-01-01'
    13                                                   AND l_shipdate <  DATE '1995-01-01'
    14                                                   AND l_discount BETWEEN 0.05 AND 0.07
    15                                                   AND l_quantity < 24;
    16                                             """
    17    736.0 MiB    662.2 MiB           1       count = con.execute(query).fetchone()[0]
    18    736.0 MiB      0.0 MiB           1       print(count)
    19    736.1 MiB      0.1 MiB           1       con.close()


Memory = 665.20 MB, Time = 3.49 s

------------------------------------------------

[NORMAL] Reading a table with ca. 140.8 GB ...

------------------------------------------------

73100039
Filename: /Users/niklasniggemann/duckdb_motherduck_lab/duckdb_polars_stresstest/duckdb_olap.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
     5     71.1 MiB     71.1 MiB           1   @profile
     6                                         def normal_test(scale_factor: int):
     7     73.8 MiB      2.7 MiB           1       con = duckdb.connect()
     8     73.8 MiB      0.0 MiB           1       parquet_path = f"tpc/lineitem_{scale_factor}.parquet"
     9     73.8 MiB      0.0 MiB           2       query = f"""
    10                                                 SELECT COUNT(*) AS cnt
    11     73.8 MiB      0.0 MiB           1           FROM read_parquet('{parquet_path}')
    12                                                 WHERE l_shipdate >= DATE '1994-01-01'
    13                                                   AND l_shipdate <  DATE '1995-01-01'
    14                                                   AND l_discount BETWEEN 0.05 AND 0.07
    15                                                   AND l_quantity < 24;
    16                                             """
    17   1194.4 MiB   1120.6 MiB           1       count = con.execute(query).fetchone()[0]
    18   1194.4 MiB      0.0 MiB           1       print(count)
    19   1386.8 MiB    192.5 MiB           1       con.close()


Memory = 1315.86 MB, Time = 5.07 s

--- Elapsed Time (s) ---
Mean:   1.71
Std:    1.89
CV:     110.4%
Min:    0.10
Max:    5.07
Span:   4.97

------------------------------------------------

--- Memory Used (MB) ---
Mean:   383.00
Std:    466.62
CV:     121.8%
Min:    35.38
Max:    1315.86
Span:   1280.48

------------------------------------------------

[START] duckdb - stress

------------------------------------------------

[STRESS] Reading 2 tables with ca. 280 GB ...

------------------------------------------------

146200078
Filename: /Users/niklasniggemann/duckdb_motherduck_lab/duckdb_polars_stresstest/duckdb_olap.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    21     71.3 MiB     71.3 MiB           1   @profile
    22                                         def stress_test(scale_factors: List[int]):
    23     73.9 MiB      2.6 MiB           1       con = duckdb.connect()
    24     73.9 MiB      0.0 MiB           3       parquet_files = [f"tpc/lineitem_{sf}.parquet" for sf in scale_factors]
    25     73.9 MiB      0.0 MiB           3       files_str = ", ".join([f"'{f}'" for f in parquet_files])
    26     73.9 MiB      0.0 MiB           2       query = f"""
    27                                                 SELECT COUNT(*) AS cnt
    28     73.9 MiB      0.0 MiB           1           FROM read_parquet([{files_str}])
    29                                                 WHERE l_shipdate >= DATE '1994-01-01'
    30                                                   AND l_shipdate <  DATE '1995-01-01'
    31                                                   AND l_discount BETWEEN 0.05 AND 0.07
    32                                                   AND l_quantity < 24;
    33                                             """
    34   1668.6 MiB   1594.7 MiB           1       count = con.execute(query).fetchone()[0]
    35   1668.6 MiB      0.0 MiB           1       print(count)
    36   1715.6 MiB     47.0 MiB           1       con.close()


Memory = 1644.48 MB, Time = 9.22 s

------------------------------------------------

[STRESS] Reading 4 tables with ca. 560 GB ...

------------------------------------------------

292400156
Filename: /Users/niklasniggemann/duckdb_motherduck_lab/duckdb_polars_stresstest/duckdb_olap.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    21     71.2 MiB     71.2 MiB           1   @profile
    22                                         def stress_test(scale_factors: List[int]):
    23     73.9 MiB      2.7 MiB           1       con = duckdb.connect()
    24     73.9 MiB      0.0 MiB           5       parquet_files = [f"tpc/lineitem_{sf}.parquet" for sf in scale_factors]
    25     73.9 MiB      0.0 MiB           5       files_str = ", ".join([f"'{f}'" for f in parquet_files])
    26     73.9 MiB      0.0 MiB           2       query = f"""
    27                                                 SELECT COUNT(*) AS cnt
    28     73.9 MiB      0.0 MiB           1           FROM read_parquet([{files_str}])
    29                                                 WHERE l_shipdate >= DATE '1994-01-01'
    30                                                   AND l_shipdate <  DATE '1995-01-01'
    31                                                   AND l_discount BETWEEN 0.05 AND 0.07
    32                                                   AND l_quantity < 24;
    33                                             """
    34   2270.4 MiB   2196.5 MiB           1       count = con.execute(query).fetchone()[0]
    35   2270.4 MiB      0.1 MiB           1       print(count)
    36   2300.6 MiB     30.2 MiB           1       con.close()


Memory = 2229.61 MB, Time = 18.42 s

------------------------------------------------

[STRESS] Reading 6 tables with ca. 840 GB ...

------------------------------------------------

438600234
Filename: /Users/niklasniggemann/duckdb_motherduck_lab/duckdb_polars_stresstest/duckdb_olap.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    21     71.1 MiB     71.1 MiB           1   @profile
    22                                         def stress_test(scale_factors: List[int]):
    23     73.7 MiB      2.6 MiB           1       con = duckdb.connect()
    24     73.7 MiB      0.0 MiB           7       parquet_files = [f"tpc/lineitem_{sf}.parquet" for sf in scale_factors]
    25     73.7 MiB      0.0 MiB           7       files_str = ", ".join([f"'{f}'" for f in parquet_files])
    26     73.7 MiB      0.0 MiB           2       query = f"""
    27                                                 SELECT COUNT(*) AS cnt
    28     73.7 MiB      0.0 MiB           1           FROM read_parquet([{files_str}])
    29                                                 WHERE l_shipdate >= DATE '1994-01-01'
    30                                                   AND l_shipdate <  DATE '1995-01-01'
    31                                                   AND l_discount BETWEEN 0.05 AND 0.07
    32                                                   AND l_quantity < 24;
    33                                             """
    34   3030.0 MiB   2956.3 MiB           1       count = con.execute(query).fetchone()[0]
    35   3030.0 MiB      0.0 MiB           1       print(count)
    36   3038.7 MiB      8.6 MiB           1       con.close()


Memory = 2967.81 MB, Time = 27.62 s

------------------------------------------------

[STRESS] Reading 8 tables with ca. 1120 GB ...

------------------------------------------------

584800312
Filename: /Users/niklasniggemann/duckdb_motherduck_lab/duckdb_polars_stresstest/duckdb_olap.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    21     71.2 MiB     71.2 MiB           1   @profile
    22                                         def stress_test(scale_factors: List[int]):
    23     73.8 MiB      2.7 MiB           1       con = duckdb.connect()
    24     73.8 MiB      0.0 MiB           9       parquet_files = [f"tpc/lineitem_{sf}.parquet" for sf in scale_factors]
    25     73.8 MiB      0.0 MiB           9       files_str = ", ".join([f"'{f}'" for f in parquet_files])
    26     73.8 MiB      0.0 MiB           2       query = f"""
    27                                                 SELECT COUNT(*) AS cnt
    28     73.8 MiB      0.0 MiB           1           FROM read_parquet([{files_str}])
    29                                                 WHERE l_shipdate >= DATE '1994-01-01'
    30                                                   AND l_shipdate <  DATE '1995-01-01'
    31                                                   AND l_discount BETWEEN 0.05 AND 0.07
    32                                                   AND l_quantity < 24;
    33                                             """
    34   4201.5 MiB   4127.7 MiB           1       count = con.execute(query).fetchone()[0]
    35   4201.6 MiB      0.1 MiB           1       print(count)
    36   4230.4 MiB     28.8 MiB           1       con.close()


Memory = 4159.38 MB, Time = 36.11 s

--- Elapsed Time (s) ---
Mean:   22.84
Std:    11.60
CV:     50.8%
Min:    9.22
Max:    36.11
Span:   26.89

------------------------------------------------

--- Memory Used (MB) ---
Mean:   2750.32
Std:    1084.25
CV:     39.4%
Min:    1644.48
Max:    4159.38
Span:   2514.90

------------------------------------------------

[START] duckdb - multiple

------------------------------------------------

[MULTIPLE] Reading 2 files (ca. 4 GB total)...

------------------------------------------------

2278528
Filename: /Users/niklasniggemann/duckdb_motherduck_lab/duckdb_polars_stresstest/duckdb_olap.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    38     71.2 MiB     71.2 MiB           1   @profile
    39                                         def multiple_test(num_files: int):
    40     73.9 MiB      2.8 MiB           1       con = duckdb.connect()
    41     73.9 MiB      0.0 MiB           1       parquet_files = [f"tpc/lineitem_10.parquet"] * num_files
    42     73.9 MiB      0.0 MiB           3       files_str = ", ".join([f"'{f}'" for f in parquet_files])
    43     73.9 MiB      0.0 MiB           2       query = f"""
    44                                                 SELECT COUNT(*) AS cnt
    45     73.9 MiB      0.0 MiB           1           FROM read_parquet([{files_str}])
    46                                                 WHERE l_shipdate >= DATE '1994-01-01'
    47                                                   AND l_shipdate <  DATE '1995-01-01'
    48                                                   AND l_discount BETWEEN 0.05 AND 0.07
    49                                                   AND l_quantity < 24;
    50                                             """
    51    115.8 MiB     41.9 MiB           1       count = con.execute(query).fetchone()[0]
    52    115.8 MiB      0.0 MiB           1       print(count)
    53    115.7 MiB     -0.1 MiB           1       con.close()


Memory = 44.73 MB, Time = 0.20 s

------------------------------------------------

[MULTIPLE] Reading 4 files (ca. 8 GB total)...

------------------------------------------------

4557056
Filename: /Users/niklasniggemann/duckdb_motherduck_lab/duckdb_polars_stresstest/duckdb_olap.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    38     71.2 MiB     71.2 MiB           1   @profile
    39                                         def multiple_test(num_files: int):
    40     74.0 MiB      2.7 MiB           1       con = duckdb.connect()
    41     74.0 MiB      0.0 MiB           1       parquet_files = [f"tpc/lineitem_10.parquet"] * num_files
    42     74.0 MiB      0.0 MiB           5       files_str = ", ".join([f"'{f}'" for f in parquet_files])
    43     74.0 MiB      0.0 MiB           2       query = f"""
    44                                                 SELECT COUNT(*) AS cnt
    45     74.0 MiB      0.0 MiB           1           FROM read_parquet([{files_str}])
    46                                                 WHERE l_shipdate >= DATE '1994-01-01'
    47                                                   AND l_shipdate <  DATE '1995-01-01'
    48                                                   AND l_discount BETWEEN 0.05 AND 0.07
    49                                                   AND l_quantity < 24;
    50                                             """
    51    127.5 MiB     53.5 MiB           1       count = con.execute(query).fetchone()[0]
    52    127.5 MiB      0.0 MiB           1       print(count)
    53    127.4 MiB     -0.1 MiB           1       con.close()


Memory = 56.31 MB, Time = 0.26 s

------------------------------------------------

[MULTIPLE] Reading 9 files (ca. 18 GB total)...

------------------------------------------------

10253376
Filename: /Users/niklasniggemann/duckdb_motherduck_lab/duckdb_polars_stresstest/duckdb_olap.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    38     71.0 MiB     71.0 MiB           1   @profile
    39                                         def multiple_test(num_files: int):
    40     73.7 MiB      2.7 MiB           1       con = duckdb.connect()
    41     73.8 MiB      0.0 MiB           1       parquet_files = [f"tpc/lineitem_10.parquet"] * num_files
    42     73.8 MiB      0.0 MiB          10       files_str = ", ".join([f"'{f}'" for f in parquet_files])
    43     73.8 MiB      0.0 MiB           2       query = f"""
    44                                                 SELECT COUNT(*) AS cnt
    45     73.8 MiB      0.0 MiB           1           FROM read_parquet([{files_str}])
    46                                                 WHERE l_shipdate >= DATE '1994-01-01'
    47                                                   AND l_shipdate <  DATE '1995-01-01'
    48                                                   AND l_discount BETWEEN 0.05 AND 0.07
    49                                                   AND l_quantity < 24;
    50                                             """
    51    161.4 MiB     87.7 MiB           1       count = con.execute(query).fetchone()[0]
    52    161.4 MiB      0.0 MiB           1       print(count)
    53    161.3 MiB     -0.1 MiB           1       con.close()


Memory = 90.50 MB, Time = 0.56 s

------------------------------------------------

[MULTIPLE] Reading 18 files (ca. 36 GB total)...

------------------------------------------------

20506752
Filename: /Users/niklasniggemann/duckdb_motherduck_lab/duckdb_polars_stresstest/duckdb_olap.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    38     71.1 MiB     71.1 MiB           1   @profile
    39                                         def multiple_test(num_files: int):
    40     73.8 MiB      2.7 MiB           1       con = duckdb.connect()
    41     73.8 MiB      0.0 MiB           1       parquet_files = [f"tpc/lineitem_10.parquet"] * num_files
    42     73.8 MiB      0.0 MiB          19       files_str = ", ".join([f"'{f}'" for f in parquet_files])
    43     73.8 MiB      0.0 MiB           2       query = f"""
    44                                                 SELECT COUNT(*) AS cnt
    45     73.8 MiB      0.0 MiB           1           FROM read_parquet([{files_str}])
    46                                                 WHERE l_shipdate >= DATE '1994-01-01'
    47                                                   AND l_shipdate <  DATE '1995-01-01'
    48                                                   AND l_discount BETWEEN 0.05 AND 0.07
    49                                                   AND l_quantity < 24;
    50                                             """
    51    175.6 MiB    101.8 MiB           1       count = con.execute(query).fetchone()[0]
    52    175.6 MiB      0.0 MiB           1       print(count)
    53    175.6 MiB     -0.1 MiB           1       con.close()


Memory = 104.62 MB, Time = 1.06 s

------------------------------------------------

[MULTIPLE] Reading 36 files (ca. 72 GB total)...

------------------------------------------------

41013504
Filename: /Users/niklasniggemann/duckdb_motherduck_lab/duckdb_polars_stresstest/duckdb_olap.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    38     71.2 MiB     71.2 MiB           1   @profile
    39                                         def multiple_test(num_files: int):
    40     73.8 MiB      2.6 MiB           1       con = duckdb.connect()
    41     73.8 MiB      0.0 MiB           1       parquet_files = [f"tpc/lineitem_10.parquet"] * num_files
    42     73.8 MiB      0.0 MiB          37       files_str = ", ".join([f"'{f}'" for f in parquet_files])
    43     73.8 MiB      0.0 MiB           2       query = f"""
    44                                                 SELECT COUNT(*) AS cnt
    45     73.8 MiB      0.0 MiB           1           FROM read_parquet([{files_str}])
    46                                                 WHERE l_shipdate >= DATE '1994-01-01'
    47                                                   AND l_shipdate <  DATE '1995-01-01'
    48                                                   AND l_discount BETWEEN 0.05 AND 0.07
    49                                                   AND l_quantity < 24;
    50                                             """
    51    188.9 MiB    115.1 MiB           1       count = con.execute(query).fetchone()[0]
    52    188.9 MiB      0.0 MiB           1       print(count)
    53    188.8 MiB     -0.1 MiB           1       con.close()


Memory = 117.78 MB, Time = 2.03 s

------------------------------------------------

[MULTIPLE] Reading 72 files (ca. 144 GB total)...

------------------------------------------------

82027008
Filename: /Users/niklasniggemann/duckdb_motherduck_lab/duckdb_polars_stresstest/duckdb_olap.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    38     71.2 MiB     71.2 MiB           1   @profile
    39                                         def multiple_test(num_files: int):
    40     73.9 MiB      2.7 MiB           1       con = duckdb.connect()
    41     73.9 MiB      0.0 MiB           1       parquet_files = [f"tpc/lineitem_10.parquet"] * num_files
    42     73.9 MiB      0.0 MiB          73       files_str = ", ".join([f"'{f}'" for f in parquet_files])
    43     73.9 MiB      0.0 MiB           2       query = f"""
    44                                                 SELECT COUNT(*) AS cnt
    45     73.9 MiB      0.0 MiB           1           FROM read_parquet([{files_str}])
    46                                                 WHERE l_shipdate >= DATE '1994-01-01'
    47                                                   AND l_shipdate <  DATE '1995-01-01'
    48                                                   AND l_discount BETWEEN 0.05 AND 0.07
    49                                                   AND l_quantity < 24;
    50                                             """
    51    176.9 MiB    103.0 MiB           1       count = con.execute(query).fetchone()[0]
    52    176.9 MiB      0.0 MiB           1       print(count)
    53    176.8 MiB     -0.1 MiB           1       con.close()


Memory = 105.83 MB, Time = 4.00 s

--- Elapsed Time (s) ---
Mean:   1.35
Std:    1.46
CV:     108.2%
Min:    0.20
Max:    4.00
Span:   3.80

------------------------------------------------

--- Memory Used (MB) ---
Mean:   86.63
Std:    29.50
CV:     34.1%
Min:    44.73
Max:    117.78
Span:   73.05

------------------------------------------------

=== Phase 2: Plotting figures (saving to disk) ===
Plot saved to results/polars_duckdb_normal_memory.png
Plot saved to results/polars_duckdb_normal_time.png
Plot saved to results/polars_duckdb_stress_memory.png
Plot saved to results/polars_duckdb_stress_time.png
Plot saved to results/polars_duckdb_multiple_memory.png
Plot saved to results/polars_duckdb_multiple_time.png
Facet plot saved to results/all_tools_all_tests_memory_facet.png
Facet plot saved to results/all_tools_all_tests_time_facet.png
