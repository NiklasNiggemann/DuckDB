
=== Phase 1: Running benchmarks ===

[START] polars - normal

------------------------------------------------

[NORMAL] Reading a table with ca. 2.2 GB ...

------------------------------------------------

1139264
Filename: /Users/niklasniggemann/duckdb_motherduck_lab/duckdb_polars_stresstest/polars_olap.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
     6     71.2 MiB     71.2 MiB           1   @profile
     7                                         def normal_test(scale_factor: int):
     8     71.2 MiB      0.0 MiB           1       parquet_path = f"tpc/lineitem_{scale_factor}.parquet"
     9    189.6 MiB      0.0 MiB           1       df = (
    10     71.5 MiB      0.3 MiB           1           pl.scan_parquet(parquet_path)
    11     72.0 MiB      0.1 MiB           2           .filter(
    12     71.8 MiB      0.3 MiB           4               (pl.col("l_shipdate") >= date(1994, 1, 1)) &
    13     71.8 MiB      0.0 MiB           1               (pl.col("l_shipdate") <  date(1995, 1, 1)) &
    14     71.8 MiB      0.0 MiB           1               (pl.col("l_discount").is_between(0.05, 0.07)) &
    15     71.8 MiB      0.0 MiB           1               (pl.col("l_quantity") < 24)
    16                                                 )
    17     72.1 MiB      0.1 MiB           1           .select(pl.len().alias("cnt"))
    18    189.6 MiB    117.5 MiB           1           .collect(engine="streaming")
    19                                             )
    20    189.7 MiB      0.1 MiB           1       print(df['cnt'][0])


Memory = 118.62 MB, Time = 0.15 s

------------------------------------------------

[NORMAL] Reading a table with ca. 4.4 GB ...

------------------------------------------------

2281119
Filename: /Users/niklasniggemann/duckdb_motherduck_lab/duckdb_polars_stresstest/polars_olap.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
     6     71.5 MiB     71.5 MiB           1   @profile
     7                                         def normal_test(scale_factor: int):
     8     71.5 MiB      0.0 MiB           1       parquet_path = f"tpc/lineitem_{scale_factor}.parquet"
     9    201.0 MiB      0.0 MiB           1       df = (
    10     71.8 MiB      0.3 MiB           1           pl.scan_parquet(parquet_path)
    11     72.3 MiB      0.1 MiB           2           .filter(
    12     72.2 MiB      0.3 MiB           4               (pl.col("l_shipdate") >= date(1994, 1, 1)) &
    13     72.1 MiB      0.0 MiB           1               (pl.col("l_shipdate") <  date(1995, 1, 1)) &
    14     72.1 MiB      0.0 MiB           1               (pl.col("l_discount").is_between(0.05, 0.07)) &
    15     72.2 MiB      0.0 MiB           1               (pl.col("l_quantity") < 24)
    16                                                 )
    17     72.4 MiB      0.1 MiB           1           .select(pl.len().alias("cnt"))
    18    201.0 MiB    128.6 MiB           1           .collect(engine="streaming")
    19                                             )
    20    201.1 MiB      0.1 MiB           1       print(df['cnt'][0])


Memory = 129.67 MB, Time = 0.28 s

------------------------------------------------

[NORMAL] Reading a table with ca. 8.8 GB ...

------------------------------------------------

4565749
Filename: /Users/niklasniggemann/duckdb_motherduck_lab/duckdb_polars_stresstest/polars_olap.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
     6     71.3 MiB     71.3 MiB           1   @profile
     7                                         def normal_test(scale_factor: int):
     8     71.3 MiB      0.0 MiB           1       parquet_path = f"tpc/lineitem_{scale_factor}.parquet"
     9    191.6 MiB      0.1 MiB           1       df = (
    10     71.5 MiB      0.3 MiB           1           pl.scan_parquet(parquet_path)
    11     72.0 MiB      0.1 MiB           2           .filter(
    12     71.9 MiB      0.3 MiB           4               (pl.col("l_shipdate") >= date(1994, 1, 1)) &
    13     71.8 MiB      0.0 MiB           1               (pl.col("l_shipdate") <  date(1995, 1, 1)) &
    14     71.9 MiB      0.0 MiB           1               (pl.col("l_discount").is_between(0.05, 0.07)) &
    15     71.9 MiB      0.0 MiB           1               (pl.col("l_quantity") < 24)
    16                                                 )
    17     72.1 MiB      0.1 MiB           1           .select(pl.len().alias("cnt"))
    18    191.5 MiB    119.4 MiB           1           .collect(engine="streaming")
    19                                             )
    20    192.7 MiB      1.1 MiB           1       print(df['cnt'][0])


Memory = 121.91 MB, Time = 0.57 s

------------------------------------------------

[NORMAL] Reading a table with ca. 17.6 GB ...

------------------------------------------------

9135381
Filename: /Users/niklasniggemann/duckdb_motherduck_lab/duckdb_polars_stresstest/polars_olap.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
     6     71.3 MiB     71.3 MiB           1   @profile
     7                                         def normal_test(scale_factor: int):
     8     71.3 MiB      0.0 MiB           1       parquet_path = f"tpc/lineitem_{scale_factor}.parquet"
     9    237.7 MiB      0.1 MiB           1       df = (
    10     71.5 MiB      0.3 MiB           1           pl.scan_parquet(parquet_path)
    11     72.0 MiB      0.1 MiB           2           .filter(
    12     71.9 MiB      0.3 MiB           4               (pl.col("l_shipdate") >= date(1994, 1, 1)) &
    13     71.8 MiB      0.0 MiB           1               (pl.col("l_shipdate") <  date(1995, 1, 1)) &
    14     71.9 MiB      0.0 MiB           1               (pl.col("l_discount").is_between(0.05, 0.07)) &
    15     71.9 MiB      0.0 MiB           1               (pl.col("l_quantity") < 24)
    16                                                 )
    17     72.1 MiB      0.1 MiB           1           .select(pl.len().alias("cnt"))
    18    237.6 MiB    165.5 MiB           1           .collect(engine="streaming")
    19                                             )
    20    239.2 MiB      1.5 MiB           1       print(df['cnt'][0])


Memory = 168.39 MB, Time = 1.09 s

------------------------------------------------

[NORMAL] Reading a table with ca. 35.2 GB ...

------------------------------------------------

18269118
Filename: /Users/niklasniggemann/duckdb_motherduck_lab/duckdb_polars_stresstest/polars_olap.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
     6     71.1 MiB     71.1 MiB           1   @profile
     7                                         def normal_test(scale_factor: int):
     8     71.1 MiB      0.0 MiB           1       parquet_path = f"tpc/lineitem_{scale_factor}.parquet"
     9    289.8 MiB      0.2 MiB           1       df = (
    10     71.4 MiB      0.3 MiB           1           pl.scan_parquet(parquet_path)
    11     71.9 MiB      0.1 MiB           2           .filter(
    12     71.8 MiB      0.3 MiB           4               (pl.col("l_shipdate") >= date(1994, 1, 1)) &
    13     71.7 MiB      0.0 MiB           1               (pl.col("l_shipdate") <  date(1995, 1, 1)) &
    14     71.7 MiB      0.0 MiB           1               (pl.col("l_discount").is_between(0.05, 0.07)) &
    15     71.8 MiB      0.0 MiB           1               (pl.col("l_quantity") < 24)
    16                                                 )
    17     72.0 MiB      0.1 MiB           1           .select(pl.len().alias("cnt"))
    18    289.6 MiB    217.6 MiB           1           .collect(engine="streaming")
    19                                             )
    20    291.5 MiB      1.7 MiB           1       print(df['cnt'][0])


Memory = 221.27 MB, Time = 2.17 s

------------------------------------------------

[NORMAL] Reading a table with ca. 70.4 GB ...

------------------------------------------------

36542597
Filename: /Users/niklasniggemann/duckdb_motherduck_lab/duckdb_polars_stresstest/polars_olap.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
     6     71.2 MiB     71.2 MiB           1   @profile
     7                                         def normal_test(scale_factor: int):
     8     71.2 MiB      0.0 MiB           1       parquet_path = f"tpc/lineitem_{scale_factor}.parquet"
     9    472.4 MiB      0.1 MiB           1       df = (
    10     71.5 MiB      0.3 MiB           1           pl.scan_parquet(parquet_path)
    11     71.9 MiB      0.1 MiB           2           .filter(
    12     71.8 MiB      0.3 MiB           4               (pl.col("l_shipdate") >= date(1994, 1, 1)) &
    13     71.7 MiB      0.0 MiB           1               (pl.col("l_shipdate") <  date(1995, 1, 1)) &
    14     71.8 MiB      0.0 MiB           1               (pl.col("l_discount").is_between(0.05, 0.07)) &
    15     71.8 MiB      0.0 MiB           1               (pl.col("l_quantity") < 24)
    16                                                 )
    17     72.0 MiB      0.1 MiB           1           .select(pl.len().alias("cnt"))
    18    472.3 MiB    400.3 MiB           1           .collect(engine="streaming")
    19                                             )
    20    474.2 MiB      1.8 MiB           1       print(df['cnt'][0])


Memory = 403.95 MB, Time = 4.34 s

------------------------------------------------

[NORMAL] Reading a table with ca. 140.8 GB ...

------------------------------------------------

73100039
Filename: /Users/niklasniggemann/duckdb_motherduck_lab/duckdb_polars_stresstest/polars_olap.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
     6     71.2 MiB     71.2 MiB           1   @profile
     7                                         def normal_test(scale_factor: int):
     8     71.2 MiB      0.0 MiB           1       parquet_path = f"tpc/lineitem_{scale_factor}.parquet"
     9    732.6 MiB      0.1 MiB           1       df = (
    10     71.5 MiB      0.3 MiB           1           pl.scan_parquet(parquet_path)
    11     72.0 MiB      0.1 MiB           2           .filter(
    12     71.8 MiB      0.3 MiB           4               (pl.col("l_shipdate") >= date(1994, 1, 1)) &
    13     71.8 MiB      0.0 MiB           1               (pl.col("l_shipdate") <  date(1995, 1, 1)) &
    14     71.8 MiB      0.0 MiB           1               (pl.col("l_discount").is_between(0.05, 0.07)) &
    15     71.8 MiB      0.0 MiB           1               (pl.col("l_quantity") < 24)
    16                                                 )
    17     72.1 MiB      0.1 MiB           1           .select(pl.len().alias("cnt"))
    18    732.5 MiB    660.4 MiB           1           .collect(engine="streaming")
    19                                             )
    20    734.1 MiB      1.5 MiB           1       print(df['cnt'][0])


Memory = 663.88 MB, Time = 9.69 s

--- Elapsed Time (s) ---
Mean:   2.61
Std:    3.45
CV:     131.9%
Min:    0.15
Max:    9.69
Span:   9.54

------------------------------------------------

--- Memory Used (MB) ---
Mean:   261.10
Std:    204.03
CV:     78.1%
Min:    118.62
Max:    663.88
Span:   545.26

------------------------------------------------

[START] polars - stress

------------------------------------------------

[STRESS] Reading 2 tables with ca. 280 GB ...

------------------------------------------------

146200078
Filename: /Users/niklasniggemann/duckdb_motherduck_lab/duckdb_polars_stresstest/polars_olap.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    22     70.8 MiB     70.8 MiB           1   @profile
    23                                         def stress_test(scale_factors: List[int]):
    24     70.8 MiB      0.0 MiB           3       parquet_files = [f"tpc/lineitem_{sf}.parquet" for sf in scale_factors]
    25   1382.1 MiB      0.1 MiB           1       df = (
    26     71.0 MiB      0.3 MiB           1           pl.scan_parquet(parquet_files)
    27     71.5 MiB      0.1 MiB           2           .filter(
    28     71.4 MiB      0.3 MiB           4               (pl.col("l_shipdate") >= date(1994, 1, 1)) &
    29     71.3 MiB      0.0 MiB           1               (pl.col("l_shipdate") <  date(1995, 1, 1)) &
    30     71.3 MiB      0.0 MiB           1               (pl.col("l_discount").is_between(0.05, 0.07)) &
    31     71.4 MiB      0.0 MiB           1               (pl.col("l_quantity") < 24)
    32                                                 )
    33     71.6 MiB      0.1 MiB           1           .select(pl.len().alias("cnt"))
    34   1382.0 MiB   1310.4 MiB           1           .collect(engine="streaming")
    35                                             )
    36   1383.9 MiB      1.8 MiB           1       print(df['cnt'][0])


Memory = 1314.05 MB, Time = 10.11 s

------------------------------------------------

[STRESS] Reading 4 tables with ca. 560 GB ...

------------------------------------------------

292400156
Filename: /Users/niklasniggemann/duckdb_motherduck_lab/duckdb_polars_stresstest/polars_olap.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    22     71.0 MiB     71.0 MiB           1   @profile
    23                                         def stress_test(scale_factors: List[int]):
    24     71.0 MiB      0.0 MiB           5       parquet_files = [f"tpc/lineitem_{sf}.parquet" for sf in scale_factors]
    25   1307.3 MiB      0.1 MiB           1       df = (
    26     71.3 MiB      0.3 MiB           1           pl.scan_parquet(parquet_files)
    27     71.8 MiB      0.1 MiB           2           .filter(
    28     71.6 MiB      0.3 MiB           4               (pl.col("l_shipdate") >= date(1994, 1, 1)) &
    29     71.5 MiB      0.0 MiB           1               (pl.col("l_shipdate") <  date(1995, 1, 1)) &
    30     71.6 MiB      0.0 MiB           1               (pl.col("l_discount").is_between(0.05, 0.07)) &
    31     71.6 MiB      0.0 MiB           1               (pl.col("l_quantity") < 24)
    32                                                 )
    33     71.8 MiB      0.1 MiB           1           .select(pl.len().alias("cnt"))
    34   1307.2 MiB   1235.4 MiB           1           .collect(engine="streaming")
    35                                             )
    36   1308.0 MiB      0.6 MiB           1       print(df['cnt'][0])


Memory = 1237.31 MB, Time = 25.91 s

------------------------------------------------

[STRESS] Reading 6 tables with ca. 840 GB ...

------------------------------------------------

438600234
Filename: /Users/niklasniggemann/duckdb_motherduck_lab/duckdb_polars_stresstest/polars_olap.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    22     71.1 MiB     71.1 MiB           1   @profile
    23                                         def stress_test(scale_factors: List[int]):
    24     71.1 MiB      0.0 MiB           7       parquet_files = [f"tpc/lineitem_{sf}.parquet" for sf in scale_factors]
    25   1273.6 MiB      0.1 MiB           1       df = (
    26     71.4 MiB      0.3 MiB           1           pl.scan_parquet(parquet_files)
    27     71.9 MiB      0.1 MiB           2           .filter(
    28     71.7 MiB      0.3 MiB           4               (pl.col("l_shipdate") >= date(1994, 1, 1)) &
    29     71.7 MiB      0.0 MiB           1               (pl.col("l_shipdate") <  date(1995, 1, 1)) &
    30     71.7 MiB      0.0 MiB           1               (pl.col("l_discount").is_between(0.05, 0.07)) &
    31     71.7 MiB      0.0 MiB           1               (pl.col("l_quantity") < 24)
    32                                                 )
    33     71.9 MiB      0.1 MiB           1           .select(pl.len().alias("cnt"))
    34   1273.5 MiB   1201.6 MiB           1           .collect(engine="streaming")
    35                                             )
    36   1275.5 MiB      1.8 MiB           1       print(df['cnt'][0])


Memory = 1205.12 MB, Time = 54.46 s

------------------------------------------------

[STRESS] Reading 8 tables with ca. 1120 GB ...

------------------------------------------------

584800312
Filename: /Users/niklasniggemann/duckdb_motherduck_lab/duckdb_polars_stresstest/polars_olap.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    22     71.2 MiB     71.2 MiB           1   @profile
    23                                         def stress_test(scale_factors: List[int]):
    24     71.2 MiB      0.0 MiB           9       parquet_files = [f"tpc/lineitem_{sf}.parquet" for sf in scale_factors]
    25   1678.3 MiB      0.2 MiB           1       df = (
    26     71.5 MiB      0.3 MiB           1           pl.scan_parquet(parquet_files)
    27     72.0 MiB      0.1 MiB           2           .filter(
    28     71.9 MiB      0.3 MiB           4               (pl.col("l_shipdate") >= date(1994, 1, 1)) &
    29     71.8 MiB      0.0 MiB           1               (pl.col("l_shipdate") <  date(1995, 1, 1)) &
    30     71.8 MiB      0.0 MiB           1               (pl.col("l_discount").is_between(0.05, 0.07)) &
    31     71.9 MiB      0.0 MiB           1               (pl.col("l_quantity") < 24)
    32                                                 )
    33     72.1 MiB      0.1 MiB           1           .select(pl.len().alias("cnt"))
    34   1678.1 MiB   1606.0 MiB           1           .collect(engine="streaming")
    35                                             )
    36   1680.1 MiB      1.8 MiB           1       print(df['cnt'][0])


Memory = 1609.72 MB, Time = 113.71 s

--- Elapsed Time (s) ---
Mean:   51.05
Std:    45.63
CV:     89.4%
Min:    10.11
Max:    113.71
Span:   103.60

------------------------------------------------

--- Memory Used (MB) ---
Mean:   1341.55
Std:    184.53
CV:     13.8%
Min:    1205.12
Max:    1609.72
Span:   404.60

------------------------------------------------

[START] polars - multiple

------------------------------------------------

[MULTIPLE] Reading 2 files (ca. 4 GB total)...

------------------------------------------------

2278528
Filename: /Users/niklasniggemann/duckdb_motherduck_lab/duckdb_polars_stresstest/polars_olap.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    38     71.2 MiB     71.2 MiB           1   @profile
    39                                         def multiple_test(num_files: int):
    40     71.2 MiB      0.0 MiB           1       parquet_files = [f"tpc/lineitem_10.parquet"] * num_files
    41    237.0 MiB      0.0 MiB           1       df = (
    42     71.4 MiB      0.3 MiB           1           pl.scan_parquet(parquet_files)
    43     71.9 MiB      0.1 MiB           2           .filter(
    44     71.8 MiB      0.3 MiB           4               (pl.col("l_shipdate") >= date(1994, 1, 1)) &
    45     71.7 MiB      0.0 MiB           1               (pl.col("l_shipdate") <  date(1995, 1, 1)) &
    46     71.8 MiB      0.0 MiB           1               (pl.col("l_discount").is_between(0.05, 0.07)) &
    47     71.8 MiB      0.0 MiB           1               (pl.col("l_quantity") < 24)
    48                                                 )
    49     72.0 MiB      0.1 MiB           1           .select(pl.len().alias("cnt"))
    50    237.0 MiB    165.0 MiB           1           .collect(engine="streaming")
    51                                             )
    52    237.1 MiB      0.1 MiB           1       print(df['cnt'][0])


Memory = 166.08 MB, Time = 0.21 s

------------------------------------------------

[MULTIPLE] Reading 4 files (ca. 8 GB total)...

------------------------------------------------

4557056
Filename: /Users/niklasniggemann/duckdb_motherduck_lab/duckdb_polars_stresstest/polars_olap.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    38     71.0 MiB     71.0 MiB           1   @profile
    39                                         def multiple_test(num_files: int):
    40     71.0 MiB      0.0 MiB           1       parquet_files = [f"tpc/lineitem_10.parquet"] * num_files
    41    370.6 MiB      0.0 MiB           1       df = (
    42     71.3 MiB      0.3 MiB           1           pl.scan_parquet(parquet_files)
    43     71.8 MiB      0.1 MiB           2           .filter(
    44     71.6 MiB      0.3 MiB           4               (pl.col("l_shipdate") >= date(1994, 1, 1)) &
    45     71.5 MiB      0.0 MiB           1               (pl.col("l_shipdate") <  date(1995, 1, 1)) &
    46     71.6 MiB      0.0 MiB           1               (pl.col("l_discount").is_between(0.05, 0.07)) &
    47     71.6 MiB      0.0 MiB           1               (pl.col("l_quantity") < 24)
    48                                                 )
    49     71.8 MiB      0.1 MiB           1           .select(pl.len().alias("cnt"))
    50    370.6 MiB    298.7 MiB           1           .collect(engine="streaming")
    51                                             )
    52    370.7 MiB      0.1 MiB           1       print(df['cnt'][0])


Memory = 299.81 MB, Time = 0.32 s

------------------------------------------------

[MULTIPLE] Reading 9 files (ca. 18 GB total)...

------------------------------------------------

10253376
Filename: /Users/niklasniggemann/duckdb_motherduck_lab/duckdb_polars_stresstest/polars_olap.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    38     71.1 MiB     71.1 MiB           1   @profile
    39                                         def multiple_test(num_files: int):
    40     71.1 MiB      0.0 MiB           1       parquet_files = [f"tpc/lineitem_10.parquet"] * num_files
    41    559.2 MiB      0.0 MiB           1       df = (
    42     71.4 MiB      0.3 MiB           1           pl.scan_parquet(parquet_files)
    43     71.9 MiB      0.1 MiB           2           .filter(
    44     71.8 MiB      0.3 MiB           4               (pl.col("l_shipdate") >= date(1994, 1, 1)) &
    45     71.7 MiB      0.0 MiB           1               (pl.col("l_shipdate") <  date(1995, 1, 1)) &
    46     71.7 MiB      0.0 MiB           1               (pl.col("l_discount").is_between(0.05, 0.07)) &
    47     71.8 MiB      0.0 MiB           1               (pl.col("l_quantity") < 24)
    48                                                 )
    49     72.0 MiB      0.1 MiB           1           .select(pl.len().alias("cnt"))
    50    559.2 MiB    487.2 MiB           1           .collect(engine="streaming")
    51                                             )
    52    559.3 MiB      0.1 MiB           1       print(df['cnt'][0])


Memory = 488.30 MB, Time = 0.67 s

------------------------------------------------

[MULTIPLE] Reading 18 files (ca. 36 GB total)...

------------------------------------------------

20506752
Filename: /Users/niklasniggemann/duckdb_motherduck_lab/duckdb_polars_stresstest/polars_olap.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    38     71.3 MiB     71.3 MiB           1   @profile
    39                                         def multiple_test(num_files: int):
    40     71.3 MiB      0.0 MiB           1       parquet_files = [f"tpc/lineitem_10.parquet"] * num_files
    41    765.5 MiB      0.1 MiB           1       df = (
    42     71.6 MiB      0.3 MiB           1           pl.scan_parquet(parquet_files)
    43     72.1 MiB      0.1 MiB           2           .filter(
    44     71.9 MiB      0.3 MiB           4               (pl.col("l_shipdate") >= date(1994, 1, 1)) &
    45     71.9 MiB      0.0 MiB           1               (pl.col("l_shipdate") <  date(1995, 1, 1)) &
    46     71.9 MiB      0.0 MiB           1               (pl.col("l_discount").is_between(0.05, 0.07)) &
    47     71.9 MiB      0.0 MiB           1               (pl.col("l_quantity") < 24)
    48                                                 )
    49     72.2 MiB      0.1 MiB           1           .select(pl.len().alias("cnt"))
    50    765.3 MiB    693.2 MiB           1           .collect(engine="streaming")
    51                                             )
    52    767.3 MiB      1.8 MiB           1       print(df['cnt'][0])


Memory = 696.88 MB, Time = 1.34 s

------------------------------------------------

[MULTIPLE] Reading 36 files (ca. 72 GB total)...

------------------------------------------------

41013504
Filename: /Users/niklasniggemann/duckdb_motherduck_lab/duckdb_polars_stresstest/polars_olap.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    38     71.1 MiB     71.1 MiB           1   @profile
    39                                         def multiple_test(num_files: int):
    40     71.1 MiB      0.0 MiB           1       parquet_files = [f"tpc/lineitem_10.parquet"] * num_files
    41    959.9 MiB      0.0 MiB           1       df = (
    42     71.4 MiB      0.3 MiB           1           pl.scan_parquet(parquet_files)
    43     71.9 MiB      0.1 MiB           2           .filter(
    44     71.7 MiB      0.3 MiB           4               (pl.col("l_shipdate") >= date(1994, 1, 1)) &
    45     71.7 MiB      0.0 MiB           1               (pl.col("l_shipdate") <  date(1995, 1, 1)) &
    46     71.7 MiB      0.0 MiB           1               (pl.col("l_discount").is_between(0.05, 0.07)) &
    47     71.7 MiB      0.0 MiB           1               (pl.col("l_quantity") < 24)
    48                                                 )
    49     72.0 MiB      0.1 MiB           1           .select(pl.len().alias("cnt"))
    50    959.9 MiB    888.0 MiB           1           .collect(engine="streaming")
    51                                             )
    52    960.0 MiB      0.1 MiB           1       print(df['cnt'][0])


Memory = 889.02 MB, Time = 2.37 s

------------------------------------------------

[MULTIPLE] Reading 72 files (ca. 144 GB total)...

------------------------------------------------

82027008
Filename: /Users/niklasniggemann/duckdb_motherduck_lab/duckdb_polars_stresstest/polars_olap.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    38     71.2 MiB     71.2 MiB           1   @profile
    39                                         def multiple_test(num_files: int):
    40     71.2 MiB      0.0 MiB           1       parquet_files = [f"tpc/lineitem_10.parquet"] * num_files
    41   1067.5 MiB      0.0 MiB           1       df = (
    42     71.5 MiB      0.3 MiB           1           pl.scan_parquet(parquet_files)
    43     72.0 MiB      0.1 MiB           2           .filter(
    44     71.9 MiB      0.3 MiB           4               (pl.col("l_shipdate") >= date(1994, 1, 1)) &
    45     71.8 MiB      0.0 MiB           1               (pl.col("l_shipdate") <  date(1995, 1, 1)) &
    46     71.8 MiB      0.0 MiB           1               (pl.col("l_discount").is_between(0.05, 0.07)) &
    47     71.9 MiB      0.0 MiB           1               (pl.col("l_quantity") < 24)
    48                                                 )
    49     72.1 MiB      0.1 MiB           1           .select(pl.len().alias("cnt"))
    50   1067.5 MiB    995.5 MiB           1           .collect(engine="streaming")
    51                                             )
    52   1067.7 MiB      0.1 MiB           1       print(df['cnt'][0])


Memory = 996.55 MB, Time = 4.90 s

--- Elapsed Time (s) ---
Mean:   1.64
Std:    1.79
CV:     109.3%
Min:    0.21
Max:    4.90
Span:   4.69

------------------------------------------------

--- Memory Used (MB) ---
Mean:   589.44
Std:    328.75
CV:     55.8%
Min:    166.08
Max:    996.55
Span:   830.47

------------------------------------------------

[START] duckdb - normal

------------------------------------------------

[NORMAL] Reading a table with ca. 2.2 GB ...

------------------------------------------------

1139264
Filename: /Users/niklasniggemann/duckdb_motherduck_lab/duckdb_polars_stresstest/duckdb_olap.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
     5     71.1 MiB     71.1 MiB           1   @profile
     6                                         def normal_test(scale_factor: int):
     7     73.8 MiB      2.8 MiB           1       con = duckdb.connect()
     8     73.8 MiB      0.0 MiB           1       parquet_path = f"tpc/lineitem_{scale_factor}.parquet"
     9     73.8 MiB      0.0 MiB           2       query = f"""
    10                                                 SELECT COUNT(*) AS cnt
    11     73.8 MiB      0.0 MiB           1           FROM read_parquet('{parquet_path}')
    12                                                 WHERE l_shipdate >= DATE '1994-01-01'
    13                                                   AND l_shipdate <  DATE '1995-01-01'
    14                                                   AND l_discount BETWEEN 0.05 AND 0.07
    15                                                   AND l_quantity < 24;
    16                                             """
    17    106.1 MiB     32.2 MiB           1       count = con.execute(query).fetchone()[0]
    18    106.1 MiB      0.0 MiB           1       print(count)
    19    106.0 MiB     -0.1 MiB           1       con.close()


Memory = 35.03 MB, Time = 0.09 s

------------------------------------------------

[NORMAL] Reading a table with ca. 4.4 GB ...

------------------------------------------------

2281119
Filename: /Users/niklasniggemann/duckdb_motherduck_lab/duckdb_polars_stresstest/duckdb_olap.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
     5     71.2 MiB     71.2 MiB           1   @profile
     6                                         def normal_test(scale_factor: int):
     7     73.8 MiB      2.6 MiB           1       con = duckdb.connect()
     8     73.8 MiB      0.0 MiB           1       parquet_path = f"tpc/lineitem_{scale_factor}.parquet"
     9     73.8 MiB      0.0 MiB           2       query = f"""
    10                                                 SELECT COUNT(*) AS cnt
    11     73.8 MiB      0.0 MiB           1           FROM read_parquet('{parquet_path}')
    12                                                 WHERE l_shipdate >= DATE '1994-01-01'
    13                                                   AND l_shipdate <  DATE '1995-01-01'
    14                                                   AND l_discount BETWEEN 0.05 AND 0.07
    15                                                   AND l_quantity < 24;
    16                                             """
    17    125.9 MiB     52.1 MiB           1       count = con.execute(query).fetchone()[0]
    18    125.9 MiB      0.0 MiB           1       print(count)
    19    125.8 MiB     -0.1 MiB           1       con.close()


Memory = 54.77 MB, Time = 0.24 s

------------------------------------------------

[NORMAL] Reading a table with ca. 8.8 GB ...

------------------------------------------------

4565749
Filename: /Users/niklasniggemann/duckdb_motherduck_lab/duckdb_polars_stresstest/duckdb_olap.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
     5     71.4 MiB     71.4 MiB           1   @profile
     6                                         def normal_test(scale_factor: int):
     7     74.1 MiB      2.7 MiB           1       con = duckdb.connect()
     8     74.1 MiB      0.0 MiB           1       parquet_path = f"tpc/lineitem_{scale_factor}.parquet"
     9     74.1 MiB      0.0 MiB           2       query = f"""
    10                                                 SELECT COUNT(*) AS cnt
    11     74.1 MiB      0.0 MiB           1           FROM read_parquet('{parquet_path}')
    12                                                 WHERE l_shipdate >= DATE '1994-01-01'
    13                                                   AND l_shipdate <  DATE '1995-01-01'
    14                                                   AND l_discount BETWEEN 0.05 AND 0.07
    15                                                   AND l_quantity < 24;
    16                                             """
    17    167.0 MiB     92.9 MiB           1       count = con.execute(query).fetchone()[0]
    18    167.0 MiB      0.0 MiB           1       print(count)
    19    167.0 MiB     -0.1 MiB           1       con.close()


Memory = 95.75 MB, Time = 0.45 s

------------------------------------------------

[NORMAL] Reading a table with ca. 17.6 GB ...

------------------------------------------------

9135381
Filename: /Users/niklasniggemann/duckdb_motherduck_lab/duckdb_polars_stresstest/duckdb_olap.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
     5     71.2 MiB     71.2 MiB           1   @profile
     6                                         def normal_test(scale_factor: int):
     7     73.9 MiB      2.7 MiB           1       con = duckdb.connect()
     8     73.9 MiB      0.0 MiB           1       parquet_path = f"tpc/lineitem_{scale_factor}.parquet"
     9     73.9 MiB      0.0 MiB           2       query = f"""
    10                                                 SELECT COUNT(*) AS cnt
    11     73.9 MiB      0.0 MiB           1           FROM read_parquet('{parquet_path}')
    12                                                 WHERE l_shipdate >= DATE '1994-01-01'
    13                                                   AND l_shipdate <  DATE '1995-01-01'
    14                                                   AND l_discount BETWEEN 0.05 AND 0.07
    15                                                   AND l_quantity < 24;
    16                                             """
    17    248.2 MiB    174.3 MiB           1       count = con.execute(query).fetchone()[0]
    18    248.2 MiB      0.0 MiB           1       print(count)
    19    242.1 MiB     -6.1 MiB           1       con.close()


Memory = 171.06 MB, Time = 0.89 s

------------------------------------------------

[NORMAL] Reading a table with ca. 35.2 GB ...

------------------------------------------------

18269118
Filename: /Users/niklasniggemann/duckdb_motherduck_lab/duckdb_polars_stresstest/duckdb_olap.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
     5     71.2 MiB     71.2 MiB           1   @profile
     6                                         def normal_test(scale_factor: int):
     7     73.8 MiB      2.6 MiB           1       con = duckdb.connect()
     8     73.8 MiB      0.0 MiB           1       parquet_path = f"tpc/lineitem_{scale_factor}.parquet"
     9     73.8 MiB      0.0 MiB           2       query = f"""
    10                                                 SELECT COUNT(*) AS cnt
    11     73.8 MiB      0.0 MiB           1           FROM read_parquet('{parquet_path}')
    12                                                 WHERE l_shipdate >= DATE '1994-01-01'
    13                                                   AND l_shipdate <  DATE '1995-01-01'
    14                                                   AND l_discount BETWEEN 0.05 AND 0.07
    15                                                   AND l_quantity < 24;
    16                                             """
    17    411.3 MiB    337.5 MiB           1       count = con.execute(query).fetchone()[0]
    18    411.3 MiB      0.0 MiB           1       print(count)
    19    411.3 MiB      0.0 MiB           1       con.close()


Memory = 340.27 MB, Time = 1.73 s

------------------------------------------------

[NORMAL] Reading a table with ca. 70.4 GB ...

------------------------------------------------

36542597
Filename: /Users/niklasniggemann/duckdb_motherduck_lab/duckdb_polars_stresstest/duckdb_olap.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
     5     71.2 MiB     71.2 MiB           1   @profile
     6                                         def normal_test(scale_factor: int):
     7     73.8 MiB      2.6 MiB           1       con = duckdb.connect()
     8     73.8 MiB      0.0 MiB           1       parquet_path = f"tpc/lineitem_{scale_factor}.parquet"
     9     73.8 MiB      0.0 MiB           2       query = f"""
    10                                                 SELECT COUNT(*) AS cnt
    11     73.8 MiB      0.0 MiB           1           FROM read_parquet('{parquet_path}')
    12                                                 WHERE l_shipdate >= DATE '1994-01-01'
    13                                                   AND l_shipdate <  DATE '1995-01-01'
    14                                                   AND l_discount BETWEEN 0.05 AND 0.07
    15                                                   AND l_quantity < 24;
    16                                             """
    17    736.6 MiB    662.8 MiB           1       count = con.execute(query).fetchone()[0]
    18    736.6 MiB      0.0 MiB           1       print(count)
    19    736.8 MiB      0.1 MiB           1       con.close()


Memory = 665.69 MB, Time = 3.52 s

------------------------------------------------

[NORMAL] Reading a table with ca. 140.8 GB ...

------------------------------------------------

73100039
Filename: /Users/niklasniggemann/duckdb_motherduck_lab/duckdb_polars_stresstest/duckdb_olap.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
     5     71.3 MiB     71.3 MiB           1   @profile
     6                                         def normal_test(scale_factor: int):
     7     74.1 MiB      2.8 MiB           1       con = duckdb.connect()
     8     74.1 MiB      0.0 MiB           1       parquet_path = f"tpc/lineitem_{scale_factor}.parquet"
     9     74.1 MiB      0.0 MiB           2       query = f"""
    10                                                 SELECT COUNT(*) AS cnt
    11     74.1 MiB      0.0 MiB           1           FROM read_parquet('{parquet_path}')
    12                                                 WHERE l_shipdate >= DATE '1994-01-01'
    13                                                   AND l_shipdate <  DATE '1995-01-01'
    14                                                   AND l_discount BETWEEN 0.05 AND 0.07
    15                                                   AND l_quantity < 24;
    16                                             """
    17    868.0 MiB    793.9 MiB           1       count = con.execute(query).fetchone()[0]
    18    868.0 MiB      0.0 MiB           1       print(count)
    19   1382.7 MiB    514.7 MiB           1       con.close()


Memory = 1311.62 MB, Time = 5.33 s

--- Elapsed Time (s) ---
Mean:   1.75
Std:    1.98
CV:     112.9%
Min:    0.09
Max:    5.33
Span:   5.24

------------------------------------------------

--- Memory Used (MB) ---
Mean:   382.03
Std:    465.53
CV:     121.9%
Min:    35.03
Max:    1311.62
Span:   1276.59

------------------------------------------------

[START] duckdb - stress

------------------------------------------------

[STRESS] Reading 2 tables with ca. 280 GB ...

------------------------------------------------

146200078
Filename: /Users/niklasniggemann/duckdb_motherduck_lab/duckdb_polars_stresstest/duckdb_olap.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    21     71.1 MiB     71.1 MiB           1   @profile
    22                                         def stress_test(scale_factors: List[int]):
    23     73.8 MiB      2.8 MiB           1       con = duckdb.connect()
    24     73.9 MiB      0.0 MiB           3       parquet_files = [f"tpc/lineitem_{sf}.parquet" for sf in scale_factors]
    25     73.9 MiB      0.0 MiB           3       files_str = ", ".join([f"'{f}'" for f in parquet_files])
    26     73.9 MiB      0.0 MiB           2       query = f"""
    27                                                 SELECT COUNT(*) AS cnt
    28     73.9 MiB      0.0 MiB           1           FROM read_parquet([{files_str}])
    29                                                 WHERE l_shipdate >= DATE '1994-01-01'
    30                                                   AND l_shipdate <  DATE '1995-01-01'
    31                                                   AND l_discount BETWEEN 0.05 AND 0.07
    32                                                   AND l_quantity < 24;
    33                                             """
    34   1744.6 MiB   1670.7 MiB           1       count = con.execute(query).fetchone()[0]
    35   1744.6 MiB      0.0 MiB           1       print(count)
    36   1811.2 MiB     66.6 MiB           1       con.close()


Memory = 1740.31 MB, Time = 9.69 s

------------------------------------------------

[STRESS] Reading 4 tables with ca. 560 GB ...

------------------------------------------------

292400156
Filename: /Users/niklasniggemann/duckdb_motherduck_lab/duckdb_polars_stresstest/duckdb_olap.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    21     71.3 MiB     71.3 MiB           1   @profile
    22                                         def stress_test(scale_factors: List[int]):
    23     74.0 MiB      2.6 MiB           1       con = duckdb.connect()
    24     74.0 MiB      0.0 MiB           5       parquet_files = [f"tpc/lineitem_{sf}.parquet" for sf in scale_factors]
    25     74.0 MiB      0.0 MiB           5       files_str = ", ".join([f"'{f}'" for f in parquet_files])
    26     74.0 MiB      0.0 MiB           2       query = f"""
    27                                                 SELECT COUNT(*) AS cnt
    28     74.0 MiB      0.0 MiB           1           FROM read_parquet([{files_str}])
    29                                                 WHERE l_shipdate >= DATE '1994-01-01'
    30                                                   AND l_shipdate <  DATE '1995-01-01'
    31                                                   AND l_discount BETWEEN 0.05 AND 0.07
    32                                                   AND l_quantity < 24;
    33                                             """
    34   2546.8 MiB   2472.8 MiB           1       count = con.execute(query).fetchone()[0]
    35   2546.8 MiB      0.0 MiB           1       print(count)
    36   2556.1 MiB      9.3 MiB           1       con.close()


Memory = 2484.94 MB, Time = 18.76 s

------------------------------------------------

[STRESS] Reading 6 tables with ca. 840 GB ...

------------------------------------------------

438600234
Filename: /Users/niklasniggemann/duckdb_motherduck_lab/duckdb_polars_stresstest/duckdb_olap.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    21     71.0 MiB     71.0 MiB           1   @profile
    22                                         def stress_test(scale_factors: List[int]):
    23     73.7 MiB      2.7 MiB           1       con = duckdb.connect()
    24     73.7 MiB      0.0 MiB           7       parquet_files = [f"tpc/lineitem_{sf}.parquet" for sf in scale_factors]
    25     73.7 MiB      0.0 MiB           7       files_str = ", ".join([f"'{f}'" for f in parquet_files])
    26     73.7 MiB      0.0 MiB           2       query = f"""
    27                                                 SELECT COUNT(*) AS cnt
    28     73.7 MiB      0.0 MiB           1           FROM read_parquet([{files_str}])
    29                                                 WHERE l_shipdate >= DATE '1994-01-01'
    30                                                   AND l_shipdate <  DATE '1995-01-01'
    31                                                   AND l_discount BETWEEN 0.05 AND 0.07
    32                                                   AND l_quantity < 24;
    33                                             """
    34   2969.0 MiB   2895.3 MiB           1       count = con.execute(query).fetchone()[0]
    35   2969.7 MiB      0.7 MiB           1       print(count)
    36   2996.2 MiB     26.5 MiB           1       con.close()


Memory = 2926.22 MB, Time = 29.55 s

------------------------------------------------

[STRESS] Reading 8 tables with ca. 1120 GB ...

------------------------------------------------

584800312
Filename: /Users/niklasniggemann/duckdb_motherduck_lab/duckdb_polars_stresstest/duckdb_olap.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    21     71.2 MiB     71.2 MiB           1   @profile
    22                                         def stress_test(scale_factors: List[int]):
    23     73.8 MiB      2.6 MiB           1       con = duckdb.connect()
    24     73.9 MiB      0.0 MiB           9       parquet_files = [f"tpc/lineitem_{sf}.parquet" for sf in scale_factors]
    25     73.9 MiB      0.0 MiB           9       files_str = ", ".join([f"'{f}'" for f in parquet_files])
    26     73.9 MiB      0.0 MiB           2       query = f"""
    27                                                 SELECT COUNT(*) AS cnt
    28     73.9 MiB      0.0 MiB           1           FROM read_parquet([{files_str}])
    29                                                 WHERE l_shipdate >= DATE '1994-01-01'
    30                                                   AND l_shipdate <  DATE '1995-01-01'
    31                                                   AND l_discount BETWEEN 0.05 AND 0.07
    32                                                   AND l_quantity < 24;
    33                                             """
    34   4290.8 MiB   4216.9 MiB           1       count = con.execute(query).fetchone()[0]
    35   4290.8 MiB      0.0 MiB           1       print(count)
    36   4314.2 MiB     23.4 MiB           1       con.close()


Memory = 4243.12 MB, Time = 36.65 s

--- Elapsed Time (s) ---
Mean:   23.66
Std:    11.87
CV:     50.2%
Min:    9.69
Max:    36.65
Span:   26.96

------------------------------------------------

--- Memory Used (MB) ---
Mean:   2848.65
Std:    1050.60
CV:     36.9%
Min:    1740.31
Max:    4243.12
Span:   2502.81

------------------------------------------------

[START] duckdb - multiple

------------------------------------------------

[MULTIPLE] Reading 2 files (ca. 4 GB total)...

------------------------------------------------

2278528
Filename: /Users/niklasniggemann/duckdb_motherduck_lab/duckdb_polars_stresstest/duckdb_olap.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    38     71.2 MiB     71.2 MiB           1   @profile
    39                                         def multiple_test(num_files: int):
    40     73.8 MiB      2.6 MiB           1       con = duckdb.connect()
    41     73.8 MiB      0.0 MiB           1       parquet_files = [f"tpc/lineitem_10.parquet"] * num_files
    42     73.8 MiB      0.0 MiB           3       files_str = ", ".join([f"'{f}'" for f in parquet_files])
    43     73.8 MiB      0.0 MiB           2       query = f"""
    44                                                 SELECT COUNT(*) AS cnt
    45     73.8 MiB      0.0 MiB           1           FROM read_parquet([{files_str}])
    46                                                 WHERE l_shipdate >= DATE '1994-01-01'
    47                                                   AND l_shipdate <  DATE '1995-01-01'
    48                                                   AND l_discount BETWEEN 0.05 AND 0.07
    49                                                   AND l_quantity < 24;
    50                                             """
    51    114.9 MiB     41.1 MiB           1       count = con.execute(query).fetchone()[0]
    52    114.9 MiB      0.0 MiB           1       print(count)
    53    114.8 MiB     -0.1 MiB           1       con.close()


Memory = 43.75 MB, Time = 0.19 s

------------------------------------------------

[MULTIPLE] Reading 4 files (ca. 8 GB total)...

------------------------------------------------

4557056
Filename: /Users/niklasniggemann/duckdb_motherduck_lab/duckdb_polars_stresstest/duckdb_olap.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    38     71.2 MiB     71.2 MiB           1   @profile
    39                                         def multiple_test(num_files: int):
    40     73.9 MiB      2.7 MiB           1       con = duckdb.connect()
    41     73.9 MiB      0.0 MiB           1       parquet_files = [f"tpc/lineitem_10.parquet"] * num_files
    42     73.9 MiB      0.0 MiB           5       files_str = ", ".join([f"'{f}'" for f in parquet_files])
    43     73.9 MiB      0.0 MiB           2       query = f"""
    44                                                 SELECT COUNT(*) AS cnt
    45     73.9 MiB      0.0 MiB           1           FROM read_parquet([{files_str}])
    46                                                 WHERE l_shipdate >= DATE '1994-01-01'
    47                                                   AND l_shipdate <  DATE '1995-01-01'
    48                                                   AND l_discount BETWEEN 0.05 AND 0.07
    49                                                   AND l_quantity < 24;
    50                                             """
    51    127.2 MiB     53.3 MiB           1       count = con.execute(query).fetchone()[0]
    52    127.2 MiB      0.0 MiB           1       print(count)
    53    127.1 MiB     -0.1 MiB           1       con.close()


Memory = 56.08 MB, Time = 0.27 s

------------------------------------------------

[MULTIPLE] Reading 9 files (ca. 18 GB total)...

------------------------------------------------

10253376
Filename: /Users/niklasniggemann/duckdb_motherduck_lab/duckdb_polars_stresstest/duckdb_olap.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    38     71.1 MiB     71.1 MiB           1   @profile
    39                                         def multiple_test(num_files: int):
    40     73.7 MiB      2.6 MiB           1       con = duckdb.connect()
    41     73.7 MiB      0.0 MiB           1       parquet_files = [f"tpc/lineitem_10.parquet"] * num_files
    42     73.7 MiB      0.0 MiB          10       files_str = ", ".join([f"'{f}'" for f in parquet_files])
    43     73.7 MiB      0.0 MiB           2       query = f"""
    44                                                 SELECT COUNT(*) AS cnt
    45     73.7 MiB      0.0 MiB           1           FROM read_parquet([{files_str}])
    46                                                 WHERE l_shipdate >= DATE '1994-01-01'
    47                                                   AND l_shipdate <  DATE '1995-01-01'
    48                                                   AND l_discount BETWEEN 0.05 AND 0.07
    49                                                   AND l_quantity < 24;
    50                                             """
    51    160.9 MiB     87.2 MiB           1       count = con.execute(query).fetchone()[0]
    52    160.9 MiB      0.0 MiB           1       print(count)
    53    160.8 MiB     -0.1 MiB           1       con.close()


Memory = 89.86 MB, Time = 0.53 s

------------------------------------------------

[MULTIPLE] Reading 18 files (ca. 36 GB total)...

------------------------------------------------

20506752
Filename: /Users/niklasniggemann/duckdb_motherduck_lab/duckdb_polars_stresstest/duckdb_olap.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    38     71.0 MiB     71.0 MiB           1   @profile
    39                                         def multiple_test(num_files: int):
    40     73.7 MiB      2.7 MiB           1       con = duckdb.connect()
    41     73.8 MiB      0.0 MiB           1       parquet_files = [f"tpc/lineitem_10.parquet"] * num_files
    42     73.8 MiB      0.0 MiB          19       files_str = ", ".join([f"'{f}'" for f in parquet_files])
    43     73.8 MiB      0.0 MiB           2       query = f"""
    44                                                 SELECT COUNT(*) AS cnt
    45     73.8 MiB      0.0 MiB           1           FROM read_parquet([{files_str}])
    46                                                 WHERE l_shipdate >= DATE '1994-01-01'
    47                                                   AND l_shipdate <  DATE '1995-01-01'
    48                                                   AND l_discount BETWEEN 0.05 AND 0.07
    49                                                   AND l_quantity < 24;
    50                                             """
    51    175.5 MiB    101.7 MiB           1       count = con.execute(query).fetchone()[0]
    52    175.5 MiB      0.0 MiB           1       print(count)
    53    175.4 MiB     -0.1 MiB           1       con.close()


Memory = 104.50 MB, Time = 1.14 s

------------------------------------------------

[MULTIPLE] Reading 36 files (ca. 72 GB total)...

------------------------------------------------

41013504
Filename: /Users/niklasniggemann/duckdb_motherduck_lab/duckdb_polars_stresstest/duckdb_olap.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    38     71.5 MiB     71.5 MiB           1   @profile
    39                                         def multiple_test(num_files: int):
    40     74.1 MiB      2.7 MiB           1       con = duckdb.connect()
    41     74.1 MiB      0.0 MiB           1       parquet_files = [f"tpc/lineitem_10.parquet"] * num_files
    42     74.1 MiB      0.0 MiB          37       files_str = ", ".join([f"'{f}'" for f in parquet_files])
    43     74.1 MiB      0.0 MiB           2       query = f"""
    44                                                 SELECT COUNT(*) AS cnt
    45     74.1 MiB      0.0 MiB           1           FROM read_parquet([{files_str}])
    46                                                 WHERE l_shipdate >= DATE '1994-01-01'
    47                                                   AND l_shipdate <  DATE '1995-01-01'
    48                                                   AND l_discount BETWEEN 0.05 AND 0.07
    49                                                   AND l_quantity < 24;
    50                                             """
    51    176.0 MiB    101.9 MiB           1       count = con.execute(query).fetchone()[0]
    52    176.0 MiB      0.0 MiB           1       print(count)
    53    175.9 MiB     -0.1 MiB           1       con.close()


Memory = 104.62 MB, Time = 2.11 s

------------------------------------------------

[MULTIPLE] Reading 72 files (ca. 144 GB total)...

------------------------------------------------

82027008
Filename: /Users/niklasniggemann/duckdb_motherduck_lab/duckdb_polars_stresstest/duckdb_olap.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    38     71.4 MiB     71.4 MiB           1   @profile
    39                                         def multiple_test(num_files: int):
    40     74.1 MiB      2.7 MiB           1       con = duckdb.connect()
    41     74.1 MiB      0.0 MiB           1       parquet_files = [f"tpc/lineitem_10.parquet"] * num_files
    42     74.1 MiB      0.0 MiB          73       files_str = ", ".join([f"'{f}'" for f in parquet_files])
    43     74.1 MiB      0.0 MiB           2       query = f"""
    44                                                 SELECT COUNT(*) AS cnt
    45     74.1 MiB      0.0 MiB           1           FROM read_parquet([{files_str}])
    46                                                 WHERE l_shipdate >= DATE '1994-01-01'
    47                                                   AND l_shipdate <  DATE '1995-01-01'
    48                                                   AND l_discount BETWEEN 0.05 AND 0.07
    49                                                   AND l_quantity < 24;
    50                                             """
    51    178.6 MiB    104.5 MiB           1       count = con.execute(query).fetchone()[0]
    52    178.6 MiB      0.0 MiB           1       print(count)
    53    178.5 MiB     -0.1 MiB           1       con.close()


Memory = 107.22 MB, Time = 4.00 s

--- Elapsed Time (s) ---
Mean:   1.37
Std:    1.47
CV:     107.1%
Min:    0.19
Max:    4.00
Span:   3.81

------------------------------------------------

--- Memory Used (MB) ---
Mean:   84.34
Std:    27.63
CV:     32.8%
Min:    43.75
Max:    107.22
Span:   63.47

------------------------------------------------

=== Phase 2: Plotting figures (saving to disk) ===
Plot saved to results/polars_duckdb_normal_memory.png
Plot saved to results/polars_duckdb_normal_time.png
Plot saved to results/polars_duckdb_stress_memory.png
Plot saved to results/polars_duckdb_stress_time.png
Plot saved to results/polars_duckdb_multiple_memory.png
Plot saved to results/polars_duckdb_multiple_time.png
Facet plot saved to results/all_tools_all_tests_memory_facet.png
Facet plot saved to results/all_tools_all_tests_time_facet.png
